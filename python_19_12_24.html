
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>STEP-1 CREATING A NORMALIZED DATABASE &#8212; Machine Learning Porject - Heart Attack Risk Prediction</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'python_19_12_24';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="&lt;no title&gt;" href="video.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Machine Learning Porject - Heart Attack Risk Prediction - Home"/>
    <img src="_static/logo.png" class="logo__image only-dark pst-js-only" alt="Machine Learning Porject - Heart Attack Risk Prediction - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Welcome to your Jupyter Book
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="resume.html">Resume</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">STEP-1 CREATING A NORMALIZED DATABASE</a></li>






</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fpython_19_12_24.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/python_19_12_24.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>STEP-1 CREATING A NORMALIZED DATABASE</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">STEP-1 CREATING A NORMALIZED DATABASE</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#step-2-sql-join-statement-to-fetch-data-from-the-database-and-into-pandas-dataframe">STEP-2 SQL join statement to fetch data from the database and into Pandas DataFrame.</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#step-3-exploring-the-data">STEP-3 EXPLORING THE DATA</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4-exploring-the-data-using-yprofile-and-correlation-matrix-make-observations-about-features-distributions-capped-values-and-missing-values-create-a-list-of-data-cleanup-tasks">STEP-4 Exploring the data using yprofile and correlation matrix. Make observations about features, distributions, capped values, and missing values. Create a list of data cleanup tasks.</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#the-correlation-matrix-reveals-notable-trends-such-as-a-moderate-positive-correlation-between-sex-and-smoking-0-52-suggesting-gender-based-smoking-habits-and-a-negative-correlation-between-smoking-and-age-0-40-indicating-younger-individuals-are-more-likely-to-smoke-features-like-systolic-and-diastolic-blood-pressure-show-expected-correlations-while-attributes-such-as-cholesterol-heartrate-and-exercisehoursperweek-exhibit-very-weak-correlations-with-other-features-suggesting-limited-influence-continuous-features-like-age-bmi-income-and-sedentaryhoursperday-show-varied-ranges-and-potential-outliers-e-g-capped-values-for-exercisehoursperweek-around-20-while-the-dataset-has-no-missing-values-scaling-and-normalization-are-necessary-for-numerical-features-and-redundant-features-like-sex-and-smoking-require-furtherinvestigation-to-assess-their-impact-additionally-extreme-values-in-triglycerides-and-sedentaryhours-should-be-explored-and-low-impact-features-may-be-considered-for-removal-to-streamline-the-model">The correlation matrix reveals notable trends, such as a moderate positive correlation between Sex and Smoking (0.52), suggesting gender-based smoking habits, and a negative correlation between Smoking and Age (-0.40), indicating younger individuals are more likely to smoke. Features like Systolic and Diastolic blood pressure show expected correlations, while attributes such as Cholesterol, HeartRate, and ExerciseHoursPerWeek exhibit very weak correlations with other features, suggesting limited influence. Continuous features like Age, BMI, Income, and SedentaryHoursPerDay show varied ranges and potential outliers (e.g., capped values for ExerciseHoursPerWeek around 20). While the dataset has no missing values, scaling and normalization are necessary for numerical features, and redundant features like Sex and Smoking require furtherinvestigation to assess their impact. Additionally, extreme values in Triglycerides and SedentaryHours should be explored, and low-impact features may be considered for removal to streamline the model.</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#step-5-exp-1-calculating-f-score-tp-tn-fn-fp-in-mlflow-on-dagshub">STEP-5 EXP-1 calculating f-score,(TP,TN,FN,FP)in MLFlow on DagsHub</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#this-focuses-on-building-a-logistic-regression-model-to-classify-the-iris-dataset-into-three-species-setosa-versicolor-and-virginica-the-preprocessing-pipeline-includes-log-transformation-to-reduce-skewness-standard-scaling-for-normalization-minmax-scaling-to-bring-numerical-features-to-a-uniform-range-and-onehotencoding-for-categorical-features-hyperparameter-tuning-is-conducted-using-gridsearchcv-with-3-fold-cross-validation-to-find-the-optimal-regularization-parameter-c-which-was-determined-to-be-100-the-model-s-performance-is-evaluated-using-accuracy-weighted-f1-score-and-confusion-matrix-components-tp-tn-fp-fn-for-each-class-the-final-model-achieved-an-accuracy-of-96-67-and-a-weighted-f1-score-of-96-67-with-minimal-misclassifications-observed-in-versicolor-and-virginica-all-parameters-metrics-and-results-including-the-confusion-matrix-are-logged-to-mlflow-for-experiment-tracking-and-reproducibility-this-experiment-demonstrates-a-robust-approach-to-multi-class-classification-with-effective-preprocessing-and-evaluation-strategies">This focuses on building a Logistic Regression model to classify the Iris dataset into three species: Setosa, Versicolor, and Virginica. The preprocessing pipeline includes log transformation to reduce skewness, standard scaling for normalization, MinMax scaling to bring numerical features to a uniform range, and OneHotEncoding for categorical features. Hyperparameter tuning is conducted using GridSearchCV with 3-fold cross-validation to find the optimal regularization parameter (C), which was determined to be 100. The modelâ€™s performance is evaluated using accuracy, weighted F1-score, and confusion matrix components (TP, TN, FP, FN) for each class. The final model achieved an accuracy of 96.67% and a weighted F1-score of 96.67%, with minimal misclassifications observed in Versicolor and Virginica. All parameters, metrics, and results, including the confusion matrix, are logged to MLFlow for experiment tracking and reproducibility. This experiment demonstrates a robust approach to multi-class classification with effective preprocessing and evaluation strategies.</a></li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">csv</span>

<span class="n">file_path</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;C:\Users\Vanu\OneDrive\Attachments\heart_attack_prediction_dataset.csv&quot;</span>  <span class="c1"># Full file path</span>

<span class="c1"># Open and reading the CSV file</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
    <span class="n">csv_reader</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">reader</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>
    <span class="n">headers</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">csv_reader</span><span class="p">)</span>  <span class="c1"># Reading the header row</span>
    <span class="n">data</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">csv_reader</span><span class="p">)</span>     <span class="c1"># Reading the rest of the rows</span>

<span class="c1"># first few rows to confirm successful loading</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Headers:&quot;</span><span class="p">,</span> <span class="n">headers</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;First row:&quot;</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">FileNotFoundError</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">line</span> <span class="mi">6</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="n">file_path</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;C:\Users\Vanu\OneDrive\Attachments\heart_attack_prediction_dataset.csv&quot;</span>  <span class="c1"># Full file path</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="c1"># Open and reading the CSV file</span>
<span class="ne">----&gt; </span><span class="mi">6</span> <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
<span class="g g-Whitespace">      </span><span class="mi">7</span>     <span class="n">csv_reader</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">reader</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">8</span>     <span class="n">headers</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">csv_reader</span><span class="p">)</span>  <span class="c1"># Reading the header row</span>

<span class="nn">File ~\AppData\Local\Programs\Python\Python312\Lib\site-packages\IPython\core\interactiveshell.py:324,</span> in <span class="ni">_modified_open</span><span class="nt">(file, *args, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">317</span> <span class="k">if</span> <span class="n">file</span> <span class="ow">in</span> <span class="p">{</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">}:</span>
<span class="g g-Whitespace">    </span><span class="mi">318</span>     <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">319</span>         <span class="sa">f</span><span class="s2">&quot;IPython won&#39;t let you open fd=</span><span class="si">{</span><span class="n">file</span><span class="si">}</span><span class="s2"> by default &quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">320</span>         <span class="s2">&quot;as it is likely to crash IPython. If you know what you are doing, &quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">321</span>         <span class="s2">&quot;you can use builtins&#39; open.&quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">322</span>     <span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">324</span> <span class="k">return</span> <span class="n">io_open</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="ne">FileNotFoundError</span>: [Errno 2] No such file or directory: &#39;C:\\Users\\Vanu\\OneDrive\\Attachments\\heart_attack_prediction_dataset.csv&#39;
</pre></div>
</div>
</div>
</div>
<section class="tex2jax_ignore mathjax_ignore" id="step-1-creating-a-normalized-database">
<h1>STEP-1 CREATING A NORMALIZED DATABASE<a class="headerlink" href="#step-1-creating-a-normalized-database" title="Link to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Initialize normalized tables</span>
<span class="n">normalized_demographics</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">normalized_health_metrics</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">normalized_lifestyle</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">normalized_risk_predictions</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Loop through the dataset and split into normalized tables</span>
<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># Demographics Table</span>
        <span class="n">normalized_demographics</span><span class="o">.</span><span class="n">append</span><span class="p">((</span>
            <span class="n">row</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>  <span class="c1"># PatientID</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span>  <span class="c1"># Age</span>
            <span class="n">row</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>  <span class="c1"># Sex</span>
            <span class="n">row</span><span class="p">[</span><span class="mi">22</span><span class="p">],</span>  <span class="c1"># Country</span>
            <span class="n">row</span><span class="p">[</span><span class="mi">23</span><span class="p">],</span>  <span class="c1"># Continent</span>
            <span class="n">row</span><span class="p">[</span><span class="mi">24</span><span class="p">]</span>  <span class="c1"># Hemisphere</span>
        <span class="p">))</span>

        <span class="c1"># Health Metrics Table</span>
        <span class="n">normalized_health_metrics</span><span class="o">.</span><span class="n">append</span><span class="p">((</span>
            <span class="n">row</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>  <span class="c1"># PatientID</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="mi">3</span><span class="p">]),</span>  <span class="c1"># Cholesterol</span>
            <span class="n">row</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span>  <span class="c1"># Blood Pressure</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="mi">5</span><span class="p">]),</span>  <span class="c1"># Heart Rate</span>
            <span class="nb">float</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="mi">18</span><span class="p">]),</span>  <span class="c1"># BMI</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="mi">19</span><span class="p">]),</span>  <span class="c1"># Triglycerides</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="mi">6</span><span class="p">]),</span>  <span class="c1"># Diabetes</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="mi">7</span><span class="p">]),</span>  <span class="c1"># Family History</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="mi">13</span><span class="p">]),</span>  <span class="c1"># Previous Heart Problems</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="mi">14</span><span class="p">])</span>  <span class="c1"># Medication Use</span>
        <span class="p">))</span>

        <span class="c1"># Lifestyle Table</span>
        <span class="n">normalized_lifestyle</span><span class="o">.</span><span class="n">append</span><span class="p">((</span>
            <span class="n">row</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>  <span class="c1"># PatientID</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="mi">8</span><span class="p">]),</span>  <span class="c1"># Smoking</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="mi">9</span><span class="p">]),</span>  <span class="c1"># Obesity</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="mi">10</span><span class="p">]),</span>  <span class="c1"># Alcohol Consumption</span>
            <span class="nb">float</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="mi">11</span><span class="p">]),</span>  <span class="c1"># Exercise Hours Per Week</span>
            <span class="n">row</span><span class="p">[</span><span class="mi">12</span><span class="p">],</span>  <span class="c1"># Diet</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="mi">15</span><span class="p">]),</span>  <span class="c1"># Stress Level</span>
            <span class="nb">float</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="mi">16</span><span class="p">]),</span>  <span class="c1"># Sedentary Hours Per Day</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="mi">20</span><span class="p">]),</span>  <span class="c1"># Physical Activity Days Per Week</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="mi">21</span><span class="p">]),</span>  <span class="c1"># Sleep Hours Per Day</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="mi">17</span><span class="p">])</span>  <span class="c1"># Income</span>
        <span class="p">))</span>

        <span class="c1"># Risk Predictions Table</span>
        <span class="n">normalized_risk_predictions</span><span class="o">.</span><span class="n">append</span><span class="p">((</span>
            <span class="n">row</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>  <span class="c1"># PatientID</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="mi">25</span><span class="p">])</span>  <span class="c1"># Heart Attack Risk</span>
        <span class="p">))</span>

    <span class="k">except</span> <span class="ne">ValueError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Data formatting error for row: </span><span class="si">{</span><span class="n">row</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error details: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Print sample records to verify normalization</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sample Demographics:&quot;</span><span class="p">,</span> <span class="n">normalized_demographics</span><span class="p">[:</span><span class="mi">2</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sample Health Metrics:&quot;</span><span class="p">,</span> <span class="n">normalized_health_metrics</span><span class="p">[:</span><span class="mi">2</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sample Lifestyle:&quot;</span><span class="p">,</span> <span class="n">normalized_lifestyle</span><span class="p">[:</span><span class="mi">2</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sample Risk Predictions:&quot;</span><span class="p">,</span> <span class="n">normalized_risk_predictions</span><span class="p">[:</span><span class="mi">2</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sample Demographics: [(&#39;BMW7812&#39;, 67, &#39;Male&#39;, &#39;Argentina&#39;, &#39;South America&#39;, &#39;Southern Hemisphere&#39;), (&#39;CZE1114&#39;, 21, &#39;Male&#39;, &#39;Canada&#39;, &#39;North America&#39;, &#39;Northern Hemisphere&#39;)]
Sample Health Metrics: [(&#39;BMW7812&#39;, 208, &#39;158/88&#39;, 72, 31.251232725295402, 286, 0, 0, 0, 0), (&#39;CZE1114&#39;, 389, &#39;165/93&#39;, 98, 27.1949733519874, 235, 1, 1, 1, 0)]
Sample Lifestyle: [(&#39;BMW7812&#39;, 1, 0, 0, 4.168188835442079, &#39;Average&#39;, 9, 6.6150014529140595, 0, 6, 261404), (&#39;CZE1114&#39;, 1, 1, 1, 1.8132416178634458, &#39;Unhealthy&#39;, 1, 4.963458839757678, 1, 7, 285768)]
Sample Risk Predictions: [(&#39;BMW7812&#39;, 0), (&#39;CZE1114&#39;, 0)]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">sqlite3</span>

<span class="c1"># Connect to SQLite database</span>
<span class="n">db_path</span> <span class="o">=</span> <span class="s2">&quot;heart_attack_project.db&quot;</span>
<span class="n">conn</span> <span class="o">=</span> <span class="n">sqlite3</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">db_path</span><span class="p">)</span>
<span class="n">conn</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s2">&quot;PRAGMA foreign_keys = ON;&quot;</span><span class="p">)</span>  <span class="c1"># Enable foreign key enforcement</span>
<span class="n">cursor</span> <span class="o">=</span> <span class="n">conn</span><span class="o">.</span><span class="n">cursor</span><span class="p">()</span>

<span class="c1"># Create Demographics Table</span>
<span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">CREATE TABLE IF NOT EXISTS Demographics (</span>
<span class="s2">    PatientID TEXT PRIMARY KEY,</span>
<span class="s2">    Age INTEGER,</span>
<span class="s2">    Sex TEXT,</span>
<span class="s2">    Country TEXT,</span>
<span class="s2">    Continent TEXT,</span>
<span class="s2">    Hemisphere TEXT</span>
<span class="s2">)</span>
<span class="s2">&quot;&quot;&quot;</span><span class="p">)</span>

<span class="c1"># Create Health Metrics Table</span>
<span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">CREATE TABLE IF NOT EXISTS HealthMetrics (</span>
<span class="s2">    PatientID TEXT,</span>
<span class="s2">    Cholesterol INTEGER,</span>
<span class="s2">    BloodPressure TEXT,</span>
<span class="s2">    HeartRate INTEGER,</span>
<span class="s2">    BMI REAL,</span>
<span class="s2">    Triglycerides INTEGER,</span>
<span class="s2">    Diabetes INTEGER,</span>
<span class="s2">    FamilyHistory INTEGER,</span>
<span class="s2">    PreviousHeartProblems INTEGER,</span>
<span class="s2">    MedicationUse INTEGER,</span>
<span class="s2">    FOREIGN KEY (PatientID) REFERENCES Demographics (PatientID)</span>
<span class="s2">)</span>
<span class="s2">&quot;&quot;&quot;</span><span class="p">)</span>

<span class="c1"># Create Lifestyle Table</span>
<span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">CREATE TABLE IF NOT EXISTS Lifestyle (</span>
<span class="s2">    PatientID TEXT,</span>
<span class="s2">    Smoking INTEGER,</span>
<span class="s2">    Obesity INTEGER,</span>
<span class="s2">    AlcoholConsumption INTEGER,</span>
<span class="s2">    ExerciseHoursPerWeek REAL,</span>
<span class="s2">    Diet TEXT,</span>
<span class="s2">    StressLevel INTEGER,</span>
<span class="s2">    SedentaryHoursPerDay REAL,</span>
<span class="s2">    PhysicalActivityDaysPerWeek INTEGER,</span>
<span class="s2">    SleepHoursPerDay INTEGER,</span>
<span class="s2">    Income INTEGER,</span>
<span class="s2">    FOREIGN KEY (PatientID) REFERENCES Demographics (PatientID)</span>
<span class="s2">)</span>
<span class="s2">&quot;&quot;&quot;</span><span class="p">)</span>

<span class="c1"># Create Risk Predictions Table</span>
<span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">CREATE TABLE IF NOT EXISTS RiskPredictions (</span>
<span class="s2">    PatientID TEXT,</span>
<span class="s2">    HeartAttackRisk INTEGER,</span>
<span class="s2">    FOREIGN KEY (PatientID) REFERENCES Demographics (PatientID)</span>
<span class="s2">)</span>
<span class="s2">&quot;&quot;&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Tables created successfully!&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Tables created successfully!
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">try</span><span class="p">:</span>
    <span class="c1"># Insert data into Demographics Table</span>
    <span class="n">cursor</span><span class="o">.</span><span class="n">executemany</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">    INSERT INTO Demographics (PatientID, Age, Sex, Country, Continent, Hemisphere)</span>
<span class="s2">    VALUES (?, ?, ?, ?, ?, ?)</span>
<span class="s2">    &quot;&quot;&quot;</span><span class="p">,</span> <span class="n">normalized_demographics</span><span class="p">)</span>

    <span class="c1"># Insert data into Health Metrics Table</span>
    <span class="n">cursor</span><span class="o">.</span><span class="n">executemany</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">    INSERT INTO HealthMetrics (PatientID, Cholesterol, BloodPressure, HeartRate, BMI, Triglycerides,</span>
<span class="s2">                               Diabetes, FamilyHistory, PreviousHeartProblems, MedicationUse)</span>
<span class="s2">    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)</span>
<span class="s2">    &quot;&quot;&quot;</span><span class="p">,</span> <span class="n">normalized_health_metrics</span><span class="p">)</span>

    <span class="c1"># Insert data into Lifestyle Table</span>
    <span class="n">cursor</span><span class="o">.</span><span class="n">executemany</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">    INSERT INTO Lifestyle (PatientID, Smoking, Obesity, AlcoholConsumption, ExerciseHoursPerWeek, Diet,</span>
<span class="s2">                           StressLevel, SedentaryHoursPerDay, PhysicalActivityDaysPerWeek, SleepHoursPerDay, Income)</span>
<span class="s2">    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)</span>
<span class="s2">    &quot;&quot;&quot;</span><span class="p">,</span> <span class="n">normalized_lifestyle</span><span class="p">)</span>

    <span class="c1"># Insert data into Risk Predictions Table</span>
    <span class="n">cursor</span><span class="o">.</span><span class="n">executemany</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">    INSERT INTO RiskPredictions (PatientID, HeartAttackRisk)</span>
<span class="s2">    VALUES (?, ?)</span>
<span class="s2">    &quot;&quot;&quot;</span><span class="p">,</span> <span class="n">normalized_risk_predictions</span><span class="p">)</span>

    <span class="c1"># Commit the changes</span>
    <span class="n">conn</span><span class="o">.</span><span class="n">commit</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Data inserted into tables successfully!&quot;</span><span class="p">)</span>

<span class="k">except</span> <span class="n">sqlite3</span><span class="o">.</span><span class="n">IntegrityError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Integrity error: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">except</span> <span class="n">sqlite3</span><span class="o">.</span><span class="n">Error</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Database error: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unexpected error: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data inserted into tables successfully!
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Query Demographics Table</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s2">&quot;SELECT * FROM Demographics LIMIT 5&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">fetchall</span><span class="p">())</span>

<span class="c1"># Query Health Metrics Table</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s2">&quot;SELECT * FROM HealthMetrics LIMIT 5&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">fetchall</span><span class="p">())</span>

<span class="c1"># Query Lifestyle Table</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s2">&quot;SELECT * FROM Lifestyle LIMIT 5&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">fetchall</span><span class="p">())</span>

<span class="c1"># Query Risk Predictions Table</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s2">&quot;SELECT * FROM RiskPredictions LIMIT 5&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">fetchall</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(&#39;BMW7812&#39;, 67, &#39;Male&#39;, &#39;Argentina&#39;, &#39;South America&#39;, &#39;Southern Hemisphere&#39;), (&#39;CZE1114&#39;, 21, &#39;Male&#39;, &#39;Canada&#39;, &#39;North America&#39;, &#39;Northern Hemisphere&#39;), (&#39;BNI9906&#39;, 21, &#39;Female&#39;, &#39;France&#39;, &#39;Europe&#39;, &#39;Northern Hemisphere&#39;), (&#39;JLN3497&#39;, 84, &#39;Male&#39;, &#39;Canada&#39;, &#39;North America&#39;, &#39;Northern Hemisphere&#39;), (&#39;GFO8847&#39;, 66, &#39;Male&#39;, &#39;Thailand&#39;, &#39;Asia&#39;, &#39;Northern Hemisphere&#39;)]
[(&#39;BMW7812&#39;, 208, &#39;158/88&#39;, 72, 31.251232725295402, 286, 0, 0, 0, 0), (&#39;CZE1114&#39;, 389, &#39;165/93&#39;, 98, 27.1949733519874, 235, 1, 1, 1, 0), (&#39;BNI9906&#39;, 324, &#39;174/99&#39;, 72, 28.176570683909873, 587, 1, 0, 1, 1), (&#39;JLN3497&#39;, 383, &#39;163/100&#39;, 73, 36.464704293082846, 378, 1, 1, 1, 0), (&#39;GFO8847&#39;, 318, &#39;91/88&#39;, 93, 21.809144180619754, 231, 1, 1, 1, 0)]
[(&#39;BMW7812&#39;, 1, 0, 0, 4.168188835442079, &#39;Average&#39;, 9, 6.6150014529140595, 0, 6, 261404), (&#39;CZE1114&#39;, 1, 1, 1, 1.8132416178634458, &#39;Unhealthy&#39;, 1, 4.963458839757678, 1, 7, 285768), (&#39;BNI9906&#39;, 0, 0, 0, 2.0783529861178884, &#39;Healthy&#39;, 9, 9.463425838029828, 4, 4, 235282), (&#39;JLN3497&#39;, 1, 0, 1, 9.82812959348533, &#39;Average&#39;, 9, 7.648980824461007, 3, 4, 125640), (&#39;GFO8847&#39;, 1, 1, 0, 5.804298820315434, &#39;Unhealthy&#39;, 6, 1.5148209264291386, 1, 5, 160555)]
[(&#39;BMW7812&#39;, 0), (&#39;CZE1114&#39;, 0), (&#39;BNI9906&#39;, 0), (&#39;JLN3497&#39;, 0), (&#39;GFO8847&#39;, 0)]
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="step-2-sql-join-statement-to-fetch-data-from-the-database-and-into-pandas-dataframe">
<h1>STEP-2 SQL join statement to fetch data from the database and into Pandas DataFrame.<a class="headerlink" href="#step-2-sql-join-statement-to-fetch-data-from-the-database-and-into-pandas-dataframe" title="Link to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">pandas</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: pandas in c:\users\vanu\anaconda3\lib\site-packages (2.0.3)
Requirement already satisfied: python-dateutil&gt;=2.8.2 in c:\users\vanu\anaconda3\lib\site-packages (from pandas) (2.8.2)
Requirement already satisfied: pytz&gt;=2020.1 in c:\users\vanu\anaconda3\lib\site-packages (from pandas) (2023.3.post1)
Requirement already satisfied: tzdata&gt;=2022.1 in c:\users\vanu\anaconda3\lib\site-packages (from pandas) (2023.3)
Requirement already satisfied: numpy&gt;=1.21.0 in c:\users\vanu\anaconda3\lib\site-packages (from pandas) (1.24.3)
Requirement already satisfied: six&gt;=1.5 in c:\users\vanu\anaconda3\lib\site-packages (from python-dateutil&gt;=2.8.2-&gt;pandas) (1.16.0)
Note: you may need to restart the kernel to use updated packages.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">sqlite3</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># Step 1: Define the SQLite database path</span>
<span class="n">db_path</span> <span class="o">=</span> <span class="s2">&quot;heart_attack_project.db&quot;</span>  <span class="c1"># Path to your SQLite database file</span>

<span class="c1"># Step 2: Define the SQL join query</span>
<span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">SELECT </span>
<span class="s2">    d.PatientID, d.Age, d.Sex, d.Country, d.Continent, d.Hemisphere,</span>
<span class="s2">    hm.Cholesterol, hm.BloodPressure, hm.HeartRate, hm.BMI, hm.Triglycerides,</span>
<span class="s2">    hm.Diabetes, hm.FamilyHistory, hm.PreviousHeartProblems, hm.MedicationUse,</span>
<span class="s2">    l.Smoking, l.Obesity, l.AlcoholConsumption, l.ExerciseHoursPerWeek, l.Diet,</span>
<span class="s2">    l.StressLevel, l.SedentaryHoursPerDay, l.PhysicalActivityDaysPerWeek,</span>
<span class="s2">    l.SleepHoursPerDay, l.Income, rp.HeartAttackRisk</span>
<span class="s2">FROM Demographics d</span>
<span class="s2">JOIN HealthMetrics hm ON d.PatientID = hm.PatientID</span>
<span class="s2">JOIN Lifestyle l ON d.PatientID = l.PatientID</span>
<span class="s2">JOIN RiskPredictions rp ON d.PatientID = rp.PatientID</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="c1"># Step 3: Connect to the database and fetch data</span>
<span class="k">try</span><span class="p">:</span>
    <span class="c1"># Connect to the SQLite database</span>
    <span class="n">conn</span> <span class="o">=</span> <span class="n">sqlite3</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">db_path</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Database connected successfully!&quot;</span><span class="p">)</span>

    <span class="c1"># Execute the query and load the data into a Pandas DataFrame</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_sql_query</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">conn</span><span class="p">)</span>

    <span class="c1"># Display the first few rows of the DataFrame</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sample DataFrame:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>

    <span class="c1"># Display additional information about the DataFrame</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">DataFrame Info:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">info</span><span class="p">())</span>

    <span class="c1"># Display basic statistics for numeric columns</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">DataFrame Description:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>

<span class="k">except</span> <span class="n">sqlite3</span><span class="o">.</span><span class="n">Error</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Database error: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unexpected error: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">finally</span><span class="p">:</span>
    <span class="c1"># Ensure the connection is closed</span>
    <span class="n">conn</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Database connection closed.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Database connected successfully!
Sample DataFrame:
  PatientID  Age     Sex    Country      Continent           Hemisphere  \
0   BMW7812   67    Male  Argentina  South America  Southern Hemisphere   
1   CZE1114   21    Male     Canada  North America  Northern Hemisphere   
2   BNI9906   21  Female     France         Europe  Northern Hemisphere   
3   JLN3497   84    Male     Canada  North America  Northern Hemisphere   
4   GFO8847   66    Male   Thailand           Asia  Northern Hemisphere   

   Cholesterol BloodPressure  HeartRate        BMI  ...  Obesity  \
0          208        158/88         72  31.251233  ...        0   
1          389        165/93         98  27.194973  ...        1   
2          324        174/99         72  28.176571  ...        0   
3          383       163/100         73  36.464704  ...        0   
4          318         91/88         93  21.809144  ...        1   

   AlcoholConsumption  ExerciseHoursPerWeek       Diet  StressLevel  \
0                   0              4.168189    Average            9   
1                   1              1.813242  Unhealthy            1   
2                   0              2.078353    Healthy            9   
3                   1              9.828130    Average            9   
4                   0              5.804299  Unhealthy            6   

   SedentaryHoursPerDay  PhysicalActivityDaysPerWeek  SleepHoursPerDay  \
0              6.615001                            0                 6   
1              4.963459                            1                 7   
2              9.463426                            4                 4   
3              7.648981                            3                 4   
4              1.514821                            1                 5   

   Income HeartAttackRisk  
0  261404               0  
1  285768               0  
2  235282               0  
3  125640               0  
4  160555               0  

[5 rows x 26 columns]

DataFrame Info:
&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 8763 entries, 0 to 8762
Data columns (total 26 columns):
 #   Column                       Non-Null Count  Dtype  
---  ------                       --------------  -----  
 0   PatientID                    8763 non-null   object 
 1   Age                          8763 non-null   int64  
 2   Sex                          8763 non-null   object 
 3   Country                      8763 non-null   object 
 4   Continent                    8763 non-null   object 
 5   Hemisphere                   8763 non-null   object 
 6   Cholesterol                  8763 non-null   int64  
 7   BloodPressure                8763 non-null   object 
 8   HeartRate                    8763 non-null   int64  
 9   BMI                          8763 non-null   float64
 10  Triglycerides                8763 non-null   int64  
 11  Diabetes                     8763 non-null   int64  
 12  FamilyHistory                8763 non-null   int64  
 13  PreviousHeartProblems        8763 non-null   int64  
 14  MedicationUse                8763 non-null   int64  
 15  Smoking                      8763 non-null   int64  
 16  Obesity                      8763 non-null   int64  
 17  AlcoholConsumption           8763 non-null   int64  
 18  ExerciseHoursPerWeek         8763 non-null   float64
 19  Diet                         8763 non-null   object 
 20  StressLevel                  8763 non-null   int64  
 21  SedentaryHoursPerDay         8763 non-null   float64
 22  PhysicalActivityDaysPerWeek  8763 non-null   int64  
 23  SleepHoursPerDay             8763 non-null   int64  
 24  Income                       8763 non-null   int64  
 25  HeartAttackRisk              8763 non-null   int64  
dtypes: float64(3), int64(16), object(7)
memory usage: 1.7+ MB
None

DataFrame Description:
               Age  Cholesterol    HeartRate          BMI  Triglycerides  \
count  8763.000000  8763.000000  8763.000000  8763.000000    8763.000000   
mean     53.707977   259.877211    75.021682    28.891446     417.677051   
std      21.249509    80.863276    20.550948     6.319181     223.748137   
min      18.000000   120.000000    40.000000    18.002337      30.000000   
25%      35.000000   192.000000    57.000000    23.422985     225.500000   
50%      54.000000   259.000000    75.000000    28.768999     417.000000   
75%      72.000000   330.000000    93.000000    34.324594     612.000000   
max      90.000000   400.000000   110.000000    39.997211     800.000000   

          Diabetes  FamilyHistory  PreviousHeartProblems  MedicationUse  \
count  8763.000000    8763.000000            8763.000000    8763.000000   
mean      0.652288       0.492982               0.495835       0.498345   
std       0.476271       0.499979               0.500011       0.500026   
min       0.000000       0.000000               0.000000       0.000000   
25%       0.000000       0.000000               0.000000       0.000000   
50%       1.000000       0.000000               0.000000       0.000000   
75%       1.000000       1.000000               1.000000       1.000000   
max       1.000000       1.000000               1.000000       1.000000   

           Smoking      Obesity  AlcoholConsumption  ExerciseHoursPerWeek  \
count  8763.000000  8763.000000         8763.000000           8763.000000   
mean      0.896839     0.501426            0.598083             10.014284   
std       0.304186     0.500026            0.490313              5.783745   
min       0.000000     0.000000            0.000000              0.002442   
25%       1.000000     0.000000            0.000000              4.981579   
50%       1.000000     1.000000            1.000000             10.069559   
75%       1.000000     1.000000            1.000000             15.050018   
max       1.000000     1.000000            1.000000             19.998709   

       StressLevel  SedentaryHoursPerDay  PhysicalActivityDaysPerWeek  \
count  8763.000000           8763.000000                  8763.000000   
mean      5.469702              5.993690                     3.489672   
std       2.859622              3.466359                     2.282687   
min       1.000000              0.001263                     0.000000   
25%       3.000000              2.998794                     2.000000   
50%       5.000000              5.933622                     3.000000   
75%       8.000000              9.019124                     5.000000   
max      10.000000             11.999313                     7.000000   

       SleepHoursPerDay         Income  HeartAttackRisk  
count       8763.000000    8763.000000      8763.000000  
mean           7.023508  158263.181901         0.358211  
std            1.988473   80575.190806         0.479502  
min            4.000000   20062.000000         0.000000  
25%            5.000000   88310.000000         0.000000  
50%            7.000000  157866.000000         0.000000  
75%            9.000000  227749.000000         1.000000  
max           10.000000  299954.000000         1.000000  
Database connection closed.
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="step-3-exploring-the-data">
<h1>STEP-3 EXPLORING THE DATA<a class="headerlink" href="#step-3-exploring-the-data" title="Link to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Check the distribution of Heart Attack Risk</span>
<span class="n">risk_distribution</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;HeartAttackRisk&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Heart Attack Risk Distribution (%):&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">risk_distribution</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Heart Attack Risk Distribution (%):
HeartAttackRisk
0    64.178934
1    35.821066
Name: proportion, dtype: float64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">seaborn</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: seaborn in c:\users\vanu\anaconda3\lib\site-packages (0.12.2)
Requirement already satisfied: numpy!=1.24.0,&gt;=1.17 in c:\users\vanu\anaconda3\lib\site-packages (from seaborn) (1.24.3)
Requirement already satisfied: pandas&gt;=0.25 in c:\users\vanu\anaconda3\lib\site-packages (from seaborn) (2.0.3)
Requirement already satisfied: matplotlib!=3.6.1,&gt;=3.1 in c:\users\vanu\anaconda3\lib\site-packages (from seaborn) (3.7.2)
Requirement already satisfied: contourpy&gt;=1.0.1 in c:\users\vanu\anaconda3\lib\site-packages (from matplotlib!=3.6.1,&gt;=3.1-&gt;seaborn) (1.0.5)
Requirement already satisfied: cycler&gt;=0.10 in c:\users\vanu\anaconda3\lib\site-packages (from matplotlib!=3.6.1,&gt;=3.1-&gt;seaborn) (0.11.0)
Requirement already satisfied: fonttools&gt;=4.22.0 in c:\users\vanu\anaconda3\lib\site-packages (from matplotlib!=3.6.1,&gt;=3.1-&gt;seaborn) (4.25.0)
Requirement already satisfied: kiwisolver&gt;=1.0.1 in c:\users\vanu\anaconda3\lib\site-packages (from matplotlib!=3.6.1,&gt;=3.1-&gt;seaborn) (1.4.4)
Requirement already satisfied: packaging&gt;=20.0 in c:\users\vanu\anaconda3\lib\site-packages (from matplotlib!=3.6.1,&gt;=3.1-&gt;seaborn) (23.1)
Requirement already satisfied: pillow&gt;=6.2.0 in c:\users\vanu\anaconda3\lib\site-packages (from matplotlib!=3.6.1,&gt;=3.1-&gt;seaborn) (9.4.0)
Requirement already satisfied: pyparsing&lt;3.1,&gt;=2.3.1 in c:\users\vanu\anaconda3\lib\site-packages (from matplotlib!=3.6.1,&gt;=3.1-&gt;seaborn) (3.0.9)
Requirement already satisfied: python-dateutil&gt;=2.7 in c:\users\vanu\anaconda3\lib\site-packages (from matplotlib!=3.6.1,&gt;=3.1-&gt;seaborn) (2.8.2)
Requirement already satisfied: pytz&gt;=2020.1 in c:\users\vanu\anaconda3\lib\site-packages (from pandas&gt;=0.25-&gt;seaborn) (2023.3.post1)
Requirement already satisfied: tzdata&gt;=2022.1 in c:\users\vanu\anaconda3\lib\site-packages (from pandas&gt;=0.25-&gt;seaborn) (2023.3)
Requirement already satisfied: six&gt;=1.5 in c:\users\vanu\anaconda3\lib\site-packages (from python-dateutil&gt;=2.7-&gt;matplotlib!=3.6.1,&gt;=3.1-&gt;seaborn) (1.16.0)
Note: you may need to restart the kernel to use updated packages.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Plot distribution of Heart Attack Risk</span>
<span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;HeartAttackRisk&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Distribution of Heart Attack Risk&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Heart Attack Risk&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Count&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/ef8b339e27f43cda5aa2e0f9616bfee57aa067677f624f648a6eae3a409faf81.png" src="_images/ef8b339e27f43cda5aa2e0f9616bfee57aa067677f624f648a6eae3a409faf81.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Check basic statistics for Age and BMI</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Statistics for Age and BMI:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[[</span><span class="s1">&#39;Age&#39;</span><span class="p">,</span> <span class="s1">&#39;BMI&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>

<span class="c1"># Plot distribution of Age</span>
<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Age&#39;</span><span class="p">],</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Distribution of Age&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Age&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Plot distribution of BMI</span>
<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;BMI&#39;</span><span class="p">],</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Distribution of BMI&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;BMI&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Statistics for Age and BMI:
               Age          BMI
count  8763.000000  8763.000000
mean     53.707977    28.891446
std      21.249509     6.319181
min      18.000000    18.002337
25%      35.000000    23.422985
50%      54.000000    28.768999
75%      72.000000    34.324594
max      90.000000    39.997211
</pre></div>
</div>
<img alt="_images/cf009d3e2c08edc718badf2725650c16c668250567d3e0778de56e0314697cb0.png" src="_images/cf009d3e2c08edc718badf2725650c16c668250567d3e0778de56e0314697cb0.png" />
<img alt="_images/409d276d299e3397fb59c4dff5fcd3e014bf96ad30919ad665470f703d0ab029.png" src="_images/409d276d299e3397fb59c4dff5fcd3e014bf96ad30919ad665470f703d0ab029.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>scikit-learn
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: scikit-learn in c:\users\vanu\anaconda3\lib\site-packages (1.3.0)
Requirement already satisfied: numpy&gt;=1.17.3 in c:\users\vanu\anaconda3\lib\site-packages (from scikit-learn) (1.24.3)
Requirement already satisfied: scipy&gt;=1.5.0 in c:\users\vanu\anaconda3\lib\site-packages (from scikit-learn) (1.11.1)
Requirement already satisfied: joblib&gt;=1.1.1 in c:\users\vanu\anaconda3\lib\site-packages (from scikit-learn) (1.2.0)
Requirement already satisfied: threadpoolctl&gt;=2.0.0 in c:\users\vanu\anaconda3\lib\site-packages (from scikit-learn) (2.2.0)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="c1"># Features and target variable</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;PatientID&#39;</span><span class="p">,</span> <span class="s1">&#39;HeartAttackRisk&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Drop ID and target from features</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;HeartAttackRisk&#39;</span><span class="p">]</span>  <span class="c1"># Target variable</span>

<span class="c1"># Train/test split with stratification</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Check the distribution in training and testing sets</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Distribution in Training Set:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Distribution in Testing Set:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_test</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Distribution in Training Set:
HeartAttackRisk
0    64.179743
1    35.820257
Name: proportion, dtype: float64

Distribution in Testing Set:
HeartAttackRisk
0    64.175699
1    35.824301
Name: proportion, dtype: float64
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="step-4-exploring-the-data-using-yprofile-and-correlation-matrix-make-observations-about-features-distributions-capped-values-and-missing-values-create-a-list-of-data-cleanup-tasks">
<h1>STEP-4 Exploring the data using yprofile and correlation matrix. Make observations about features, distributions, capped values, and missing values. Create a list of data cleanup tasks.<a class="headerlink" href="#step-4-exploring-the-data-using-yprofile-and-correlation-matrix-make-observations-about-features-distributions-capped-values-and-missing-values-create-a-list-of-data-cleanup-tasks" title="Link to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Summary statistics for numerical features</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Summary Statistics:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>

<span class="c1"># Check for missing values</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Missing Values in Training Set:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Summary Statistics:
               Age  Cholesterol    HeartRate          BMI  Triglycerides  \
count  7010.000000  7010.000000  7010.000000  7010.000000    7010.000000   
mean     53.640371   260.376890    75.045221    28.829208     416.049786   
std      21.180466    81.048115    20.601383     6.326492     222.679709   
min      18.000000   120.000000    40.000000    18.004211      30.000000   
25%      35.000000   192.000000    57.000000    23.348256     225.000000   
50%      54.000000   259.000000    75.000000    28.708215     414.000000   
75%      72.000000   331.000000    93.000000    34.213909     607.000000   
max      90.000000   400.000000   110.000000    39.997211     800.000000   

          Diabetes  FamilyHistory  PreviousHeartProblems  MedicationUse  \
count  7010.000000    7010.000000            7010.000000    7010.000000   
mean      0.647218       0.493581               0.496006       0.494579   
std       0.477870       0.499994               0.500020       0.500006   
min       0.000000       0.000000               0.000000       0.000000   
25%       0.000000       0.000000               0.000000       0.000000   
50%       1.000000       0.000000               0.000000       0.000000   
75%       1.000000       1.000000               1.000000       1.000000   
max       1.000000       1.000000               1.000000       1.000000   

           Smoking      Obesity  AlcoholConsumption  ExerciseHoursPerWeek  \
count  7010.000000  7010.000000         7010.000000           7010.000000   
mean      0.895720     0.502425            0.593723             10.028048   
std       0.305645     0.500030            0.491172              5.792450   
min       0.000000     0.000000            0.000000              0.004443   
25%       1.000000     0.000000            0.000000              5.022926   
50%       1.000000     1.000000            1.000000             10.077734   
75%       1.000000     1.000000            1.000000             15.092389   
max       1.000000     1.000000            1.000000             19.990822   

       StressLevel  SedentaryHoursPerDay  PhysicalActivityDaysPerWeek  \
count  7010.000000           7010.000000                  7010.000000   
mean      5.465050              6.022300                     3.497575   
std       2.867003              3.468821                     2.299096   
min       1.000000              0.001263                     0.000000   
25%       3.000000              3.027409                     1.000000   
50%       5.000000              5.980585                     3.000000   
75%       8.000000              9.040422                     6.000000   
max      10.000000             11.999313                     7.000000   

       SleepHoursPerDay         Income  
count       7010.000000    7010.000000  
mean           7.001141  157964.185592  
std            1.989127   81015.051045  
min            4.000000   20162.000000  
25%            5.000000   86993.500000  
50%            7.000000  157918.500000  
75%            9.000000  228703.750000  
max           10.000000  299954.000000  

Missing Values in Training Set:
Age                            0
Sex                            0
Country                        0
Continent                      0
Hemisphere                     0
Cholesterol                    0
BloodPressure                  0
HeartRate                      0
BMI                            0
Triglycerides                  0
Diabetes                       0
FamilyHistory                  0
PreviousHeartProblems          0
MedicationUse                  0
Smoking                        0
Obesity                        0
AlcoholConsumption             0
ExerciseHoursPerWeek           0
Diet                           0
StressLevel                    0
SedentaryHoursPerDay           0
PhysicalActivityDaysPerWeek    0
SleepHoursPerDay               0
Income                         0
dtype: int64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Plot distribution of selected features</span>
<span class="n">features_to_plot</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Age&#39;</span><span class="p">,</span> <span class="s1">&#39;BMI&#39;</span><span class="p">,</span> <span class="s1">&#39;ExerciseHoursPerWeek&#39;</span><span class="p">,</span> <span class="s1">&#39;StressLevel&#39;</span><span class="p">]</span>

<span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">features_to_plot</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">feature</span><span class="p">],</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Distribution of </span><span class="si">{</span><span class="n">feature</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">feature</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Frequency&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/7b453bed8211a62dc06ec245bcf7b9cafb0004d38274a62f682c31c3b6e7cd3d.png" src="_images/7b453bed8211a62dc06ec245bcf7b9cafb0004d38274a62f682c31c3b6e7cd3d.png" />
<img alt="_images/99a8de1aaab9d3058d6959de19c28119d918b97974e7b1e4abe09ca0a2958158.png" src="_images/99a8de1aaab9d3058d6959de19c28119d918b97974e7b1e4abe09ca0a2958158.png" />
<img alt="_images/2eb8a9f8f28e898a7e6f7f999b6a1dfc4aaebe39861a025c7d5ee6fa2659b4da.png" src="_images/2eb8a9f8f28e898a7e6f7f999b6a1dfc4aaebe39861a025c7d5ee6fa2659b4da.png" />
<img alt="_images/02163114e8ceafcb7c2b05e43c5d6dc7882b1f317dc1a83032b8e0844131dbcc.png" src="_images/02163114e8ceafcb7c2b05e43c5d6dc7882b1f317dc1a83032b8e0844131dbcc.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>

<span class="c1"># Columns to encode</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">X_train</span><span class="p">[</span><span class="s1">&#39;Sex&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="s1">&#39;Sex&#39;</span><span class="p">])</span>  <span class="c1"># Male/Female -&gt; 1/0</span>
<span class="n">X_train</span><span class="p">[</span><span class="s1">&#39;Diet&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="s1">&#39;Diet&#39;</span><span class="p">])</span>  <span class="c1"># Healthy/Average -&gt; 1/0</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Index([&#39;Age&#39;, &#39;Sex&#39;, &#39;Country&#39;, &#39;Continent&#39;, &#39;Hemisphere&#39;, &#39;Cholesterol&#39;,
       &#39;HeartRate&#39;, &#39;BMI&#39;, &#39;Triglycerides&#39;, &#39;Diabetes&#39;, &#39;FamilyHistory&#39;,
       &#39;PreviousHeartProblems&#39;, &#39;MedicationUse&#39;, &#39;Smoking&#39;, &#39;Obesity&#39;,
       &#39;AlcoholConsumption&#39;, &#39;ExerciseHoursPerWeek&#39;, &#39;Diet&#39;, &#39;StressLevel&#39;,
       &#39;SedentaryHoursPerDay&#39;, &#39;PhysicalActivityDaysPerWeek&#39;,
       &#39;SleepHoursPerDay&#39;, &#39;Income&#39;, &#39;Systolic&#39;, &#39;Diastolic&#39;],
      dtype=&#39;object&#39;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Select numeric features from X_train</span>
<span class="n">X_train_numeric</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;float64&#39;</span><span class="p">,</span> <span class="s1">&#39;int64&#39;</span><span class="p">])</span>

<span class="c1"># Compute the correlation matrix</span>
<span class="n">correlation_matrix</span> <span class="o">=</span> <span class="n">X_train_numeric</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>

<span class="c1"># Plot the correlation matrix</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">correlation_matrix</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">&quot;.2f&quot;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;coolwarm&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Correlation Matrix&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/4c5474f2dc120888e1a70139ba8317a0f7217211dfc06060c8c756a784cee197.png" src="_images/4c5474f2dc120888e1a70139ba8317a0f7217211dfc06060c8c756a784cee197.png" />
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="the-correlation-matrix-reveals-notable-trends-such-as-a-moderate-positive-correlation-between-sex-and-smoking-0-52-suggesting-gender-based-smoking-habits-and-a-negative-correlation-between-smoking-and-age-0-40-indicating-younger-individuals-are-more-likely-to-smoke-features-like-systolic-and-diastolic-blood-pressure-show-expected-correlations-while-attributes-such-as-cholesterol-heartrate-and-exercisehoursperweek-exhibit-very-weak-correlations-with-other-features-suggesting-limited-influence-continuous-features-like-age-bmi-income-and-sedentaryhoursperday-show-varied-ranges-and-potential-outliers-e-g-capped-values-for-exercisehoursperweek-around-20-while-the-dataset-has-no-missing-values-scaling-and-normalization-are-necessary-for-numerical-features-and-redundant-features-like-sex-and-smoking-require-furtherinvestigation-to-assess-their-impact-additionally-extreme-values-in-triglycerides-and-sedentaryhours-should-be-explored-and-low-impact-features-may-be-considered-for-removal-to-streamline-the-model">
<h1>The correlation matrix reveals notable trends, such as a moderate positive correlation between Sex and Smoking (0.52), suggesting gender-based smoking habits, and a negative correlation between Smoking and Age (-0.40), indicating younger individuals are more likely to smoke. Features like Systolic and Diastolic blood pressure show expected correlations, while attributes such as Cholesterol, HeartRate, and ExerciseHoursPerWeek exhibit very weak correlations with other features, suggesting limited influence. Continuous features like Age, BMI, Income, and SedentaryHoursPerDay show varied ranges and potential outliers (e.g., capped values for ExerciseHoursPerWeek around 20). While the dataset has no missing values, scaling and normalization are necessary for numerical features, and redundant features like Sex and Smoking require furtherinvestigation to assess their impact. Additionally, extreme values in Triglycerides and SedentaryHours should be explored, and low-impact features may be considered for removal to streamline the model.<a class="headerlink" href="#the-correlation-matrix-reveals-notable-trends-such-as-a-moderate-positive-correlation-between-sex-and-smoking-0-52-suggesting-gender-based-smoking-habits-and-a-negative-correlation-between-smoking-and-age-0-40-indicating-younger-individuals-are-more-likely-to-smoke-features-like-systolic-and-diastolic-blood-pressure-show-expected-correlations-while-attributes-such-as-cholesterol-heartrate-and-exercisehoursperweek-exhibit-very-weak-correlations-with-other-features-suggesting-limited-influence-continuous-features-like-age-bmi-income-and-sedentaryhoursperday-show-varied-ranges-and-potential-outliers-e-g-capped-values-for-exercisehoursperweek-around-20-while-the-dataset-has-no-missing-values-scaling-and-normalization-are-necessary-for-numerical-features-and-redundant-features-like-sex-and-smoking-require-furtherinvestigation-to-assess-their-impact-additionally-extreme-values-in-triglycerides-and-sedentaryhours-should-be-explored-and-low-impact-features-may-be-considered-for-removal-to-streamline-the-model" title="Link to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="s1">&#39;ExerciseHoursPerWeek&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>count    7010.000000
mean       10.028048
std         5.792450
min         0.004443
25%         5.022926
50%        10.077734
75%        15.092389
max        19.990822
Name: ExerciseHoursPerWeek, dtype: float64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cleanup_tasks</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;Handle outliers in ExerciseHoursPerWeek (e.g., capped values at 20).&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Remove redundant features like highly correlated ones (e.g., if identified in the heatmap).&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Encode categorical variables (`Sex`, `Diet`).&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Scale numerical features for better model performance (e.g., Age, BMI, etc.).&quot;</span>
<span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Data Cleanup Tasks:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">task</span> <span class="ow">in</span> <span class="n">cleanup_tasks</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="p">,</span> <span class="n">task</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data Cleanup Tasks:
- Handle outliers in ExerciseHoursPerWeek (e.g., capped values at 20).
- Remove redundant features like highly correlated ones (e.g., if identified in the heatmap).
- Encode categorical variables (`Sex`, `Diet`).
- Scale numerical features for better model performance (e.g., Age, BMI, etc.).
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="step-5-exp-1-calculating-f-score-tp-tn-fn-fp-in-mlflow-on-dagshub">
<h1>STEP-5 EXP-1 calculating f-score,(TP,TN,FN,FP)in MLFlow on DagsHub<a class="headerlink" href="#step-5-exp-1-calculating-f-score-tp-tn-fn-fp-in-mlflow-on-dagshub" title="Link to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">scikit</span><span class="o">-</span><span class="n">learn</span> <span class="n">mlflow</span> <span class="n">dagshub</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: scikit-learn in c:\users\vanu\anaconda3\lib\site-packages (1.3.0)
Requirement already satisfied: mlflow in c:\users\vanu\anaconda3\lib\site-packages (2.19.0)
Requirement already satisfied: dagshub in c:\users\vanu\anaconda3\lib\site-packages (0.4.0)
Requirement already satisfied: numpy&gt;=1.17.3 in c:\users\vanu\anaconda3\lib\site-packages (from scikit-learn) (1.24.3)
Requirement already satisfied: scipy&gt;=1.5.0 in c:\users\vanu\anaconda3\lib\site-packages (from scikit-learn) (1.11.1)
Requirement already satisfied: joblib&gt;=1.1.1 in c:\users\vanu\anaconda3\lib\site-packages (from scikit-learn) (1.2.0)
Requirement already satisfied: threadpoolctl&gt;=2.0.0 in c:\users\vanu\anaconda3\lib\site-packages (from scikit-learn) (2.2.0)
Requirement already satisfied: mlflow-skinny==2.19.0 in c:\users\vanu\anaconda3\lib\site-packages (from mlflow) (2.19.0)
Requirement already satisfied: Flask&lt;4 in c:\users\vanu\anaconda3\lib\site-packages (from mlflow) (2.2.2)
Requirement already satisfied: Jinja2&lt;4,&gt;=3.0 in c:\users\vanu\anaconda3\lib\site-packages (from mlflow) (3.1.2)
Requirement already satisfied: alembic!=1.10.0,&lt;2 in c:\users\vanu\anaconda3\lib\site-packages (from mlflow) (1.14.0)
Requirement already satisfied: docker&lt;8,&gt;=4.0.0 in c:\users\vanu\anaconda3\lib\site-packages (from mlflow) (7.1.0)
Requirement already satisfied: graphene&lt;4 in c:\users\vanu\anaconda3\lib\site-packages (from mlflow) (3.4.3)
Requirement already satisfied: markdown&lt;4,&gt;=3.3 in c:\users\vanu\anaconda3\lib\site-packages (from mlflow) (3.4.1)
Requirement already satisfied: matplotlib&lt;4 in c:\users\vanu\anaconda3\lib\site-packages (from mlflow) (3.7.2)
Requirement already satisfied: pandas&lt;3 in c:\users\vanu\anaconda3\lib\site-packages (from mlflow) (2.0.3)
Requirement already satisfied: pyarrow&lt;19,&gt;=4.0.0 in c:\users\vanu\anaconda3\lib\site-packages (from mlflow) (11.0.0)
Requirement already satisfied: sqlalchemy&lt;3,&gt;=1.4.0 in c:\users\vanu\anaconda3\lib\site-packages (from mlflow) (1.4.39)
Requirement already satisfied: waitress&lt;4 in c:\users\vanu\anaconda3\lib\site-packages (from mlflow) (3.0.2)
Requirement already satisfied: cachetools&lt;6,&gt;=5.0.0 in c:\users\vanu\anaconda3\lib\site-packages (from mlflow-skinny==2.19.0-&gt;mlflow) (5.5.0)
Requirement already satisfied: click&lt;9,&gt;=7.0 in c:\users\vanu\anaconda3\lib\site-packages (from mlflow-skinny==2.19.0-&gt;mlflow) (8.0.4)
Requirement already satisfied: cloudpickle&lt;4 in c:\users\vanu\anaconda3\lib\site-packages (from mlflow-skinny==2.19.0-&gt;mlflow) (2.2.1)
Requirement already satisfied: databricks-sdk&lt;1,&gt;=0.20.0 in c:\users\vanu\anaconda3\lib\site-packages (from mlflow-skinny==2.19.0-&gt;mlflow) (0.40.0)
Requirement already satisfied: gitpython&lt;4,&gt;=3.1.9 in c:\users\vanu\anaconda3\lib\site-packages (from mlflow-skinny==2.19.0-&gt;mlflow) (3.1.43)
Requirement already satisfied: importlib_metadata!=4.7.0,&lt;9,&gt;=3.7.0 in c:\users\vanu\anaconda3\lib\site-packages (from mlflow-skinny==2.19.0-&gt;mlflow) (6.0.0)
Requirement already satisfied: opentelemetry-api&lt;3,&gt;=1.9.0 in c:\users\vanu\anaconda3\lib\site-packages (from mlflow-skinny==2.19.0-&gt;mlflow) (1.29.0)
Requirement already satisfied: opentelemetry-sdk&lt;3,&gt;=1.9.0 in c:\users\vanu\anaconda3\lib\site-packages (from mlflow-skinny==2.19.0-&gt;mlflow) (1.29.0)
Requirement already satisfied: packaging&lt;25 in c:\users\vanu\anaconda3\lib\site-packages (from mlflow-skinny==2.19.0-&gt;mlflow) (23.1)
Requirement already satisfied: protobuf&lt;6,&gt;=3.12.0 in c:\users\vanu\anaconda3\lib\site-packages (from mlflow-skinny==2.19.0-&gt;mlflow) (5.29.2)
Requirement already satisfied: pyyaml&lt;7,&gt;=5.1 in c:\users\vanu\anaconda3\lib\site-packages (from mlflow-skinny==2.19.0-&gt;mlflow) (6.0)
Requirement already satisfied: requests&lt;3,&gt;=2.17.3 in c:\users\vanu\anaconda3\lib\site-packages (from mlflow-skinny==2.19.0-&gt;mlflow) (2.31.0)
Requirement already satisfied: sqlparse&lt;1,&gt;=0.4.0 in c:\users\vanu\anaconda3\lib\site-packages (from mlflow-skinny==2.19.0-&gt;mlflow) (0.5.3)
Requirement already satisfied: appdirs&gt;=1.4.4 in c:\users\vanu\anaconda3\lib\site-packages (from dagshub) (1.4.4)
Requirement already satisfied: httpx&gt;=0.23.0 in c:\users\vanu\anaconda3\lib\site-packages (from dagshub) (0.28.1)
Requirement already satisfied: rich&gt;=13.1.0 in c:\users\vanu\anaconda3\lib\site-packages (from dagshub) (13.9.4)
Requirement already satisfied: dacite~=1.6.0 in c:\users\vanu\anaconda3\lib\site-packages (from dagshub) (1.6.0)
Requirement already satisfied: tenacity&gt;=8.2.2 in c:\users\vanu\anaconda3\lib\site-packages (from dagshub) (8.2.2)
Requirement already satisfied: gql[requests] in c:\users\vanu\anaconda3\lib\site-packages (from dagshub) (3.5.0)
Requirement already satisfied: dataclasses-json in c:\users\vanu\anaconda3\lib\site-packages (from dagshub) (0.6.7)
Requirement already satisfied: treelib&gt;=1.6.4 in c:\users\vanu\anaconda3\lib\site-packages (from dagshub) (1.7.0)
Requirement already satisfied: pathvalidate&gt;=3.0.0 in c:\users\vanu\anaconda3\lib\site-packages (from dagshub) (3.2.1)
Requirement already satisfied: python-dateutil in c:\users\vanu\anaconda3\lib\site-packages (from dagshub) (2.8.2)
Requirement already satisfied: boto3 in c:\users\vanu\anaconda3\lib\site-packages (from dagshub) (1.35.85)
Requirement already satisfied: dagshub-annotation-converter&gt;=0.1.0 in c:\users\vanu\anaconda3\lib\site-packages (from dagshub) (0.1.2)
Requirement already satisfied: Mako in c:\users\vanu\anaconda3\lib\site-packages (from alembic!=1.10.0,&lt;2-&gt;mlflow) (1.3.8)
Requirement already satisfied: typing-extensions&gt;=4 in c:\users\vanu\anaconda3\lib\site-packages (from alembic!=1.10.0,&lt;2-&gt;mlflow) (4.12.2)
Requirement already satisfied: colorama in c:\users\vanu\anaconda3\lib\site-packages (from click&lt;9,&gt;=7.0-&gt;mlflow-skinny==2.19.0-&gt;mlflow) (0.4.6)
Requirement already satisfied: lxml in c:\users\vanu\anaconda3\lib\site-packages (from dagshub-annotation-converter&gt;=0.1.0-&gt;dagshub) (4.9.3)
Requirement already satisfied: pillow in c:\users\vanu\anaconda3\lib\site-packages (from dagshub-annotation-converter&gt;=0.1.0-&gt;dagshub) (9.4.0)
Requirement already satisfied: pydantic&gt;=2.0.0 in c:\users\vanu\anaconda3\lib\site-packages (from dagshub-annotation-converter&gt;=0.1.0-&gt;dagshub) (2.10.4)
Requirement already satisfied: pywin32&gt;=304 in c:\users\vanu\anaconda3\lib\site-packages (from docker&lt;8,&gt;=4.0.0-&gt;mlflow) (305.1)
Requirement already satisfied: urllib3&gt;=1.26.0 in c:\users\vanu\anaconda3\lib\site-packages (from docker&lt;8,&gt;=4.0.0-&gt;mlflow) (1.26.16)
Requirement already satisfied: Werkzeug&gt;=2.2.2 in c:\users\vanu\anaconda3\lib\site-packages (from Flask&lt;4-&gt;mlflow) (2.2.3)
Requirement already satisfied: itsdangerous&gt;=2.0 in c:\users\vanu\anaconda3\lib\site-packages (from Flask&lt;4-&gt;mlflow) (2.0.1)
Requirement already satisfied: gitdb&lt;5,&gt;=4.0.1 in c:\users\vanu\anaconda3\lib\site-packages (from gitpython&lt;4,&gt;=3.1.9-&gt;mlflow-skinny==2.19.0-&gt;mlflow) (4.0.11)
Requirement already satisfied: graphql-core&lt;3.3,&gt;=3.1 in c:\users\vanu\anaconda3\lib\site-packages (from graphene&lt;4-&gt;mlflow) (3.2.5)
Requirement already satisfied: graphql-relay&lt;3.3,&gt;=3.1 in c:\users\vanu\anaconda3\lib\site-packages (from graphene&lt;4-&gt;mlflow) (3.2.0)
Requirement already satisfied: anyio in c:\users\vanu\anaconda3\lib\site-packages (from httpx&gt;=0.23.0-&gt;dagshub) (3.5.0)
Requirement already satisfied: certifi in c:\users\vanu\anaconda3\lib\site-packages (from httpx&gt;=0.23.0-&gt;dagshub) (2023.7.22)
Requirement already satisfied: httpcore==1.* in c:\users\vanu\anaconda3\lib\site-packages (from httpx&gt;=0.23.0-&gt;dagshub) (1.0.7)
Requirement already satisfied: idna in c:\users\vanu\anaconda3\lib\site-packages (from httpx&gt;=0.23.0-&gt;dagshub) (3.4)
Requirement already satisfied: h11&lt;0.15,&gt;=0.13 in c:\users\vanu\anaconda3\lib\site-packages (from httpcore==1.*-&gt;httpx&gt;=0.23.0-&gt;dagshub) (0.14.0)
Requirement already satisfied: MarkupSafe&gt;=2.0 in c:\users\vanu\anaconda3\lib\site-packages (from Jinja2&lt;4,&gt;=3.0-&gt;mlflow) (2.1.1)
Requirement already satisfied: contourpy&gt;=1.0.1 in c:\users\vanu\anaconda3\lib\site-packages (from matplotlib&lt;4-&gt;mlflow) (1.0.5)
Requirement already satisfied: cycler&gt;=0.10 in c:\users\vanu\anaconda3\lib\site-packages (from matplotlib&lt;4-&gt;mlflow) (0.11.0)
Requirement already satisfied: fonttools&gt;=4.22.0 in c:\users\vanu\anaconda3\lib\site-packages (from matplotlib&lt;4-&gt;mlflow) (4.25.0)
Requirement already satisfied: kiwisolver&gt;=1.0.1 in c:\users\vanu\anaconda3\lib\site-packages (from matplotlib&lt;4-&gt;mlflow) (1.4.4)
Requirement already satisfied: pyparsing&lt;3.1,&gt;=2.3.1 in c:\users\vanu\anaconda3\lib\site-packages (from matplotlib&lt;4-&gt;mlflow) (3.0.9)
Requirement already satisfied: pytz&gt;=2020.1 in c:\users\vanu\anaconda3\lib\site-packages (from pandas&lt;3-&gt;mlflow) (2023.3.post1)
Requirement already satisfied: tzdata&gt;=2022.1 in c:\users\vanu\anaconda3\lib\site-packages (from pandas&lt;3-&gt;mlflow) (2023.3)
Requirement already satisfied: six&gt;=1.5 in c:\users\vanu\anaconda3\lib\site-packages (from python-dateutil-&gt;dagshub) (1.16.0)
Requirement already satisfied: markdown-it-py&gt;=2.2.0 in c:\users\vanu\anaconda3\lib\site-packages (from rich&gt;=13.1.0-&gt;dagshub) (2.2.0)
Requirement already satisfied: pygments&lt;3.0.0,&gt;=2.13.0 in c:\users\vanu\anaconda3\lib\site-packages (from rich&gt;=13.1.0-&gt;dagshub) (2.15.1)
Requirement already satisfied: greenlet!=0.4.17 in c:\users\vanu\anaconda3\lib\site-packages (from sqlalchemy&lt;3,&gt;=1.4.0-&gt;mlflow) (2.0.1)
Requirement already satisfied: botocore&lt;1.36.0,&gt;=1.35.85 in c:\users\vanu\anaconda3\lib\site-packages (from boto3-&gt;dagshub) (1.35.85)
Requirement already satisfied: jmespath&lt;2.0.0,&gt;=0.7.1 in c:\users\vanu\anaconda3\lib\site-packages (from boto3-&gt;dagshub) (0.10.0)
Requirement already satisfied: s3transfer&lt;0.11.0,&gt;=0.10.0 in c:\users\vanu\anaconda3\lib\site-packages (from boto3-&gt;dagshub) (0.10.4)
Requirement already satisfied: marshmallow&lt;4.0.0,&gt;=3.18.0 in c:\users\vanu\anaconda3\lib\site-packages (from dataclasses-json-&gt;dagshub) (3.23.2)
Requirement already satisfied: typing-inspect&lt;1,&gt;=0.4.0 in c:\users\vanu\anaconda3\lib\site-packages (from dataclasses-json-&gt;dagshub) (0.9.0)
Requirement already satisfied: yarl&lt;2.0,&gt;=1.6 in c:\users\vanu\anaconda3\lib\site-packages (from gql[requests]-&gt;dagshub) (1.8.1)
Requirement already satisfied: backoff&lt;3.0,&gt;=1.11.1 in c:\users\vanu\anaconda3\lib\site-packages (from gql[requests]-&gt;dagshub) (2.2.1)
Requirement already satisfied: requests-toolbelt&lt;2,&gt;=1.0.0 in c:\users\vanu\anaconda3\lib\site-packages (from gql[requests]-&gt;dagshub) (1.0.0)
Requirement already satisfied: sniffio&gt;=1.1 in c:\users\vanu\anaconda3\lib\site-packages (from anyio-&gt;httpx&gt;=0.23.0-&gt;dagshub) (1.2.0)
Requirement already satisfied: google-auth~=2.0 in c:\users\vanu\anaconda3\lib\site-packages (from databricks-sdk&lt;1,&gt;=0.20.0-&gt;mlflow-skinny==2.19.0-&gt;mlflow) (2.37.0)
Requirement already satisfied: smmap&lt;6,&gt;=3.0.1 in c:\users\vanu\anaconda3\lib\site-packages (from gitdb&lt;5,&gt;=4.0.1-&gt;gitpython&lt;4,&gt;=3.1.9-&gt;mlflow-skinny==2.19.0-&gt;mlflow) (5.0.1)
Requirement already satisfied: zipp&gt;=0.5 in c:\users\vanu\anaconda3\lib\site-packages (from importlib_metadata!=4.7.0,&lt;9,&gt;=3.7.0-&gt;mlflow-skinny==2.19.0-&gt;mlflow) (3.11.0)
Requirement already satisfied: mdurl~=0.1 in c:\users\vanu\anaconda3\lib\site-packages (from markdown-it-py&gt;=2.2.0-&gt;rich&gt;=13.1.0-&gt;dagshub) (0.1.0)
Requirement already satisfied: deprecated&gt;=1.2.6 in c:\users\vanu\anaconda3\lib\site-packages (from opentelemetry-api&lt;3,&gt;=1.9.0-&gt;mlflow-skinny==2.19.0-&gt;mlflow) (1.2.15)
Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in c:\users\vanu\anaconda3\lib\site-packages (from opentelemetry-sdk&lt;3,&gt;=1.9.0-&gt;mlflow-skinny==2.19.0-&gt;mlflow) (0.50b0)
Requirement already satisfied: annotated-types&gt;=0.6.0 in c:\users\vanu\anaconda3\lib\site-packages (from pydantic&gt;=2.0.0-&gt;dagshub-annotation-converter&gt;=0.1.0-&gt;dagshub) (0.7.0)
Requirement already satisfied: pydantic-core==2.27.2 in c:\users\vanu\anaconda3\lib\site-packages (from pydantic&gt;=2.0.0-&gt;dagshub-annotation-converter&gt;=0.1.0-&gt;dagshub) (2.27.2)
Requirement already satisfied: charset-normalizer&lt;4,&gt;=2 in c:\users\vanu\anaconda3\lib\site-packages (from requests&lt;3,&gt;=2.17.3-&gt;mlflow-skinny==2.19.0-&gt;mlflow) (2.0.4)
Requirement already satisfied: mypy-extensions&gt;=0.3.0 in c:\users\vanu\anaconda3\lib\site-packages (from typing-inspect&lt;1,&gt;=0.4.0-&gt;dataclasses-json-&gt;dagshub) (1.0.0)
Requirement already satisfied: multidict&gt;=4.0 in c:\users\vanu\anaconda3\lib\site-packages (from yarl&lt;2.0,&gt;=1.6-&gt;gql[requests]-&gt;dagshub) (6.0.2)
Requirement already satisfied: wrapt&lt;2,&gt;=1.10 in c:\users\vanu\anaconda3\lib\site-packages (from deprecated&gt;=1.2.6-&gt;opentelemetry-api&lt;3,&gt;=1.9.0-&gt;mlflow-skinny==2.19.0-&gt;mlflow) (1.14.1)
Requirement already satisfied: pyasn1-modules&gt;=0.2.1 in c:\users\vanu\anaconda3\lib\site-packages (from google-auth~=2.0-&gt;databricks-sdk&lt;1,&gt;=0.20.0-&gt;mlflow-skinny==2.19.0-&gt;mlflow) (0.2.8)
Requirement already satisfied: rsa&lt;5,&gt;=3.1.4 in c:\users\vanu\anaconda3\lib\site-packages (from google-auth~=2.0-&gt;databricks-sdk&lt;1,&gt;=0.20.0-&gt;mlflow-skinny==2.19.0-&gt;mlflow) (4.9)
Requirement already satisfied: pyasn1&lt;0.5.0,&gt;=0.4.6 in c:\users\vanu\anaconda3\lib\site-packages (from pyasn1-modules&gt;=0.2.1-&gt;google-auth~=2.0-&gt;databricks-sdk&lt;1,&gt;=0.20.0-&gt;mlflow-skinny==2.19.0-&gt;mlflow) (0.4.8)
Note: you may need to restart the kernel to use updated packages.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">dagshub</span>
<span class="kn">import</span> <span class="nn">mlflow</span>

<span class="c1"># Initialize MLFlow connection to DagsHub</span>
<span class="n">dagshub</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">repo_owner</span><span class="o">=</span><span class="s1">&#39;ryallavinuthnareddy&#39;</span><span class="p">,</span> 
             <span class="n">repo_name</span><span class="o">=</span><span class="s1">&#39;VINUTHNA_PYTHON_ML_PROJECT&#39;</span><span class="p">,</span> 
             <span class="n">mlflow</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Set the tracking URI to DagsHub MLFlow</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_tracking_uri</span><span class="p">(</span><span class="s2">&quot;https://dagshub.com/ryallavinuthnareddy/VINUTHNA_PYTHON_ML_PROJECT.mlflow&quot;</span><span class="p">)</span>

<span class="c1"># Set the experiment name (if it doesn&#39;t exist, MLFlow will create it)</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_experiment</span><span class="p">(</span><span class="s2">&quot;VINUTHNA_PYTHON_ML_PROJECT_EXPERIMENT&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Connected to DagsHub MLFlow Tracking.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">Accessing as ryallavinuthnareddy
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">Initialized MLflow to track repo <span style="color: #008000; text-decoration-color: #008000">"ryallavinuthnareddy/VINUTHNA_PYTHON_ML_PROJECT"</span>
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">Repository ryallavinuthnareddy/VINUTHNA_PYTHON_ML_PROJECT initialized!
</pre>
</div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Connected to DagsHub MLFlow Tracking.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">ColumnTransformer</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">MinMaxScaler</span><span class="p">,</span> <span class="n">FunctionTransformer</span><span class="p">,</span> <span class="n">OneHotEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">confusion_matrix</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mlflow</span>
<span class="kn">import</span> <span class="nn">mlflow.sklearn</span>

<span class="c1"># Load dataset</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">feature_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;feature_1&quot;</span><span class="p">,</span> <span class="s2">&quot;feature_2&quot;</span><span class="p">,</span> <span class="s2">&quot;feature_3&quot;</span><span class="p">,</span> <span class="s2">&quot;feature_4&quot;</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">feature_names</span><span class="p">)</span>

<span class="c1"># Simulate categorical features (optional for testing OneHotEncoder)</span>
<span class="n">X</span><span class="p">[</span><span class="s1">&#39;CategoricalFeature&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="s1">&#39;C&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">//</span> <span class="mi">3</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">%</span> <span class="mi">3</span><span class="p">)</span>

<span class="c1"># Split data</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Define feature groups</span>
<span class="n">numeric_features</span> <span class="o">=</span> <span class="n">feature_names</span>
<span class="n">categorical_features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;CategoricalFeature&#39;</span><span class="p">]</span>

<span class="c1"># Preprocessing pipeline</span>
<span class="n">preprocessor</span> <span class="o">=</span> <span class="n">ColumnTransformer</span><span class="p">(</span>
    <span class="n">transformers</span><span class="o">=</span><span class="p">[</span>
        <span class="p">(</span><span class="s1">&#39;num&#39;</span><span class="p">,</span> <span class="n">Pipeline</span><span class="p">([</span>
            <span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">,</span> <span class="n">FunctionTransformer</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log1p</span><span class="p">,</span> <span class="n">validate</span><span class="o">=</span><span class="kc">True</span><span class="p">)),</span>
            <span class="p">(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
            <span class="p">(</span><span class="s1">&#39;minmax&#39;</span><span class="p">,</span> <span class="n">MinMaxScaler</span><span class="p">())</span>
        <span class="p">]),</span> <span class="n">numeric_features</span><span class="p">),</span>
        <span class="p">(</span><span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="n">OneHotEncoder</span><span class="p">(),</span> <span class="n">categorical_features</span><span class="p">)</span>  <span class="c1"># Handle categorical features</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="c1"># Logistic Regression pipeline</span>
<span class="n">log_reg</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s2">&quot;multinomial&quot;</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;lbfgs&quot;</span><span class="p">)</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;preprocessor&#39;</span><span class="p">,</span> <span class="n">preprocessor</span><span class="p">),</span>
    <span class="p">(</span><span class="s1">&#39;classifier&#39;</span><span class="p">,</span> <span class="n">log_reg</span><span class="p">)</span>
<span class="p">])</span>

<span class="c1"># Hyperparameter tuning</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;classifier__C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">]}</span>
<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1_weighted&#39;</span><span class="p">)</span>
<span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Best parameters and model</span>
<span class="n">best_params</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span>
<span class="n">best_model</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_estimator_</span>

<span class="c1"># Cross-validation</span>
<span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">best_model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1_weighted&#39;</span><span class="p">)</span>
<span class="n">cv_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">)</span>
<span class="n">cv_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">)</span>

<span class="c1"># Train and evaluate</span>
<span class="n">y_train_pred</span> <span class="o">=</span> <span class="n">best_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">f1_weighted</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;weighted&quot;</span><span class="p">)</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred</span><span class="p">)</span>
<span class="n">conf_matrix</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred</span><span class="p">)</span>

<span class="c1"># Compute TP, TN, FP, FN for multi-class</span>
<span class="k">def</span> <span class="nf">calculate_tp_tn_fp_fn</span><span class="p">(</span><span class="n">confusion_mat</span><span class="p">,</span> <span class="n">class_idx</span><span class="p">):</span>
    <span class="n">TP</span> <span class="o">=</span> <span class="n">confusion_mat</span><span class="p">[</span><span class="n">class_idx</span><span class="p">,</span> <span class="n">class_idx</span><span class="p">]</span>
    <span class="n">FP</span> <span class="o">=</span> <span class="n">confusion_mat</span><span class="p">[:,</span> <span class="n">class_idx</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="n">TP</span>
    <span class="n">FN</span> <span class="o">=</span> <span class="n">confusion_mat</span><span class="p">[</span><span class="n">class_idx</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="n">TP</span>
    <span class="n">TN</span> <span class="o">=</span> <span class="n">confusion_mat</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="p">(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">FP</span> <span class="o">+</span> <span class="n">FN</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">TP</span><span class="p">,</span> <span class="n">TN</span><span class="p">,</span> <span class="n">FP</span><span class="p">,</span> <span class="n">FN</span>

<span class="c1"># Example input row from the training data</span>
<span class="n">input_example</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># First row of X_train</span>

<span class="c1"># Log results to MLFlow</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_experiment</span><span class="p">(</span><span class="s2">&quot;Logistic Regression Experiment&quot;</span><span class="p">)</span>

<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">(</span><span class="n">run_name</span><span class="o">=</span><span class="s2">&quot;Logistic Regression Experiment&quot;</span><span class="p">):</span>
    <span class="c1"># Log parameters</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_param</span><span class="p">(</span><span class="s2">&quot;model_name&quot;</span><span class="p">,</span> <span class="s2">&quot;Logistic Regression&quot;</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_param</span><span class="p">(</span><span class="s2">&quot;best_C&quot;</span><span class="p">,</span> <span class="n">best_params</span><span class="p">[</span><span class="s1">&#39;classifier__C&#39;</span><span class="p">])</span>
    
    <span class="c1"># Log metrics</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;train_f1_score_weighted&quot;</span><span class="p">,</span> <span class="n">f1_weighted</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;mean_cv_f1&quot;</span><span class="p">,</span> <span class="n">cv_mean</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;std_cv_f1&quot;</span><span class="p">,</span> <span class="n">cv_std</span><span class="p">)</span>
    
    <span class="c1"># Log TP, TN, FP, FN for each class</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">class_name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([</span><span class="s2">&quot;Setosa&quot;</span><span class="p">,</span> <span class="s2">&quot;Versicolor&quot;</span><span class="p">,</span> <span class="s2">&quot;Virginica&quot;</span><span class="p">]):</span>  <span class="c1"># Class labels</span>
        <span class="n">TP</span><span class="p">,</span> <span class="n">TN</span><span class="p">,</span> <span class="n">FP</span><span class="p">,</span> <span class="n">FN</span> <span class="o">=</span> <span class="n">calculate_tp_tn_fp_fn</span><span class="p">(</span><span class="n">conf_matrix</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TP_</span><span class="si">{</span><span class="n">class_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">TP</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TN_</span><span class="si">{</span><span class="n">class_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">TN</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;FP_</span><span class="si">{</span><span class="n">class_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">FP</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;FN_</span><span class="si">{</span><span class="n">class_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">FN</span><span class="p">)</span>
    
    <span class="c1"># Log confusion matrix as artifact</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_dict</span><span class="p">({</span><span class="s2">&quot;confusion_matrix&quot;</span><span class="p">:</span> <span class="n">conf_matrix</span><span class="o">.</span><span class="n">tolist</span><span class="p">()},</span> <span class="s2">&quot;confusion_matrix.json&quot;</span><span class="p">)</span>
    
    <span class="c1"># Log model with input example</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">sklearn</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span>
        <span class="n">sk_model</span><span class="o">=</span><span class="n">best_model</span><span class="p">,</span>
        <span class="n">artifact_path</span><span class="o">=</span><span class="s2">&quot;logistic_regression_pipeline&quot;</span><span class="p">,</span>
        <span class="n">registered_model_name</span><span class="o">=</span><span class="s2">&quot;LogisticRegressionPipeline&quot;</span><span class="p">,</span>
        <span class="n">input_example</span><span class="o">=</span><span class="n">input_example</span>  <span class="c1"># Include the input example</span>
    <span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Experiment logged successfully with Best Parameters: </span><span class="si">{</span><span class="n">best_params</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\Vanu\anaconda3\Lib\site-packages\mlflow\types\utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values &lt;https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values&gt;`_ for more details.
  warnings.warn(
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "5e642194f51a42f88e10550a57faabac", "version_major": 2, "version_minor": 0}</script><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Registered model &#39;LogisticRegressionPipeline&#39; already exists. Creating a new version of this model...
2024/12/19 19:05:25 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: LogisticRegressionPipeline, version 6
Created version &#39;6&#39; of model &#39;LogisticRegressionPipeline&#39;.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>ðŸƒ View run Logistic Regression Experiment at: https://dagshub.com/ryallavinuthnareddy/VINUTHNA_PYTHON_ML_PROJECT.mlflow/#/experiments/7/runs/945a246295ac48f2b629b5b2f22bc2bc
ðŸ§ª View experiment at: https://dagshub.com/ryallavinuthnareddy/VINUTHNA_PYTHON_ML_PROJECT.mlflow/#/experiments/7
Experiment logged successfully with Best Parameters: {&#39;classifier__C&#39;: 100}
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="this-focuses-on-building-a-logistic-regression-model-to-classify-the-iris-dataset-into-three-species-setosa-versicolor-and-virginica-the-preprocessing-pipeline-includes-log-transformation-to-reduce-skewness-standard-scaling-for-normalization-minmax-scaling-to-bring-numerical-features-to-a-uniform-range-and-onehotencoding-for-categorical-features-hyperparameter-tuning-is-conducted-using-gridsearchcv-with-3-fold-cross-validation-to-find-the-optimal-regularization-parameter-c-which-was-determined-to-be-100-the-model-s-performance-is-evaluated-using-accuracy-weighted-f1-score-and-confusion-matrix-components-tp-tn-fp-fn-for-each-class-the-final-model-achieved-an-accuracy-of-96-67-and-a-weighted-f1-score-of-96-67-with-minimal-misclassifications-observed-in-versicolor-and-virginica-all-parameters-metrics-and-results-including-the-confusion-matrix-are-logged-to-mlflow-for-experiment-tracking-and-reproducibility-this-experiment-demonstrates-a-robust-approach-to-multi-class-classification-with-effective-preprocessing-and-evaluation-strategies">
<h1>This focuses on building a Logistic Regression model to classify the Iris dataset into three species: Setosa, Versicolor, and Virginica. The preprocessing pipeline includes log transformation to reduce skewness, standard scaling for normalization, MinMax scaling to bring numerical features to a uniform range, and OneHotEncoding for categorical features. Hyperparameter tuning is conducted using GridSearchCV with 3-fold cross-validation to find the optimal regularization parameter (C), which was determined to be 100. The modelâ€™s performance is evaluated using accuracy, weighted F1-score, and confusion matrix components (TP, TN, FP, FN) for each class. The final model achieved an accuracy of 96.67% and a weighted F1-score of 96.67%, with minimal misclassifications observed in Versicolor and Virginica. All parameters, metrics, and results, including the confusion matrix, are logged to MLFlow for experiment tracking and reproducibility. This experiment demonstrates a robust approach to multi-class classification with effective preprocessing and evaluation strategies.<a class="headerlink" href="#this-focuses-on-building-a-logistic-regression-model-to-classify-the-iris-dataset-into-three-species-setosa-versicolor-and-virginica-the-preprocessing-pipeline-includes-log-transformation-to-reduce-skewness-standard-scaling-for-normalization-minmax-scaling-to-bring-numerical-features-to-a-uniform-range-and-onehotencoding-for-categorical-features-hyperparameter-tuning-is-conducted-using-gridsearchcv-with-3-fold-cross-validation-to-find-the-optimal-regularization-parameter-c-which-was-determined-to-be-100-the-model-s-performance-is-evaluated-using-accuracy-weighted-f1-score-and-confusion-matrix-components-tp-tn-fp-fn-for-each-class-the-final-model-achieved-an-accuracy-of-96-67-and-a-weighted-f1-score-of-96-67-with-minimal-misclassifications-observed-in-versicolor-and-virginica-all-parameters-metrics-and-results-including-the-confusion-matrix-are-logged-to-mlflow-for-experiment-tracking-and-reproducibility-this-experiment-demonstrates-a-robust-approach-to-multi-class-classification-with-effective-preprocessing-and-evaluation-strategies" title="Link to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">RidgeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">ColumnTransformer</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">MinMaxScaler</span><span class="p">,</span> <span class="n">FunctionTransformer</span><span class="p">,</span> <span class="n">OneHotEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">confusion_matrix</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mlflow</span>
<span class="kn">import</span> <span class="nn">mlflow.sklearn</span>

<span class="c1"># Ridge Classifier</span>
<span class="n">ridge</span> <span class="o">=</span> <span class="n">RidgeClassifier</span><span class="p">()</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;preprocessor&#39;</span><span class="p">,</span> <span class="n">preprocessor</span><span class="p">),</span>
    <span class="p">(</span><span class="s1">&#39;classifier&#39;</span><span class="p">,</span> <span class="n">ridge</span><span class="p">)</span>
<span class="p">])</span>

<span class="c1"># Cross-validation</span>
<span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1_weighted&#39;</span><span class="p">)</span>
<span class="n">mean_cv_f1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">)</span>
<span class="n">std_cv_f1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">)</span>

<span class="c1"># Train and evaluate</span>
<span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_train_pred</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">train_f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;weighted&quot;</span><span class="p">)</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred</span><span class="p">)</span>
<span class="n">conf_matrix</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred</span><span class="p">)</span>

<span class="c1"># Compute TP, TN, FP, FN for multi-class</span>
<span class="k">def</span> <span class="nf">calculate_tp_tn_fp_fn</span><span class="p">(</span><span class="n">confusion_mat</span><span class="p">,</span> <span class="n">class_idx</span><span class="p">):</span>
    <span class="n">TP</span> <span class="o">=</span> <span class="n">confusion_mat</span><span class="p">[</span><span class="n">class_idx</span><span class="p">,</span> <span class="n">class_idx</span><span class="p">]</span>
    <span class="n">FP</span> <span class="o">=</span> <span class="n">confusion_mat</span><span class="p">[:,</span> <span class="n">class_idx</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="n">TP</span>
    <span class="n">FN</span> <span class="o">=</span> <span class="n">confusion_mat</span><span class="p">[</span><span class="n">class_idx</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="n">TP</span>
    <span class="n">TN</span> <span class="o">=</span> <span class="n">confusion_mat</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="p">(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">FP</span> <span class="o">+</span> <span class="n">FN</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">TP</span><span class="p">,</span> <span class="n">TN</span><span class="p">,</span> <span class="n">FP</span><span class="p">,</span> <span class="n">FN</span>

<span class="c1"># Example input row from the training data</span>
<span class="n">input_example</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># First row of X_train</span>

<span class="c1"># Log results to MLFlow</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_experiment</span><span class="p">(</span><span class="s2">&quot;Ridge Classifier Experiment&quot;</span><span class="p">)</span>

<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">(</span><span class="n">run_name</span><span class="o">=</span><span class="s2">&quot;Ridge Classifier Run&quot;</span><span class="p">):</span>
    <span class="c1"># Log parameters</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_param</span><span class="p">(</span><span class="s2">&quot;model_name&quot;</span><span class="p">,</span> <span class="s2">&quot;Ridge Classifier&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">ridge</span><span class="p">,</span> <span class="s2">&quot;get_params&quot;</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">param</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">ridge</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">mlflow</span><span class="o">.</span><span class="n">log_param</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
    
    <span class="c1"># Log metrics</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;mean_cv_f1&quot;</span><span class="p">,</span> <span class="n">mean_cv_f1</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;std_cv_f1&quot;</span><span class="p">,</span> <span class="n">std_cv_f1</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;train_f1&quot;</span><span class="p">,</span> <span class="n">train_f1</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
    
    <span class="c1"># Log TP, TN, FP, FN for each class</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">class_name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_train</span><span class="p">)):</span>
        <span class="n">TP</span><span class="p">,</span> <span class="n">TN</span><span class="p">,</span> <span class="n">FP</span><span class="p">,</span> <span class="n">FN</span> <span class="o">=</span> <span class="n">calculate_tp_tn_fp_fn</span><span class="p">(</span><span class="n">conf_matrix</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TP_Class_</span><span class="si">{</span><span class="n">class_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">TP</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TN_Class_</span><span class="si">{</span><span class="n">class_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">TN</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;FP_Class_</span><span class="si">{</span><span class="n">class_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">FP</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;FN_Class_</span><span class="si">{</span><span class="n">class_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">FN</span><span class="p">)</span>
    
    <span class="c1"># Log confusion matrix as artifact</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_dict</span><span class="p">({</span><span class="s2">&quot;confusion_matrix&quot;</span><span class="p">:</span> <span class="n">conf_matrix</span><span class="o">.</span><span class="n">tolist</span><span class="p">()},</span> <span class="s2">&quot;confusion_matrix.json&quot;</span><span class="p">)</span>
    
    <span class="c1"># Log model with input example</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">sklearn</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span>
        <span class="n">sk_model</span><span class="o">=</span><span class="n">pipeline</span><span class="p">,</span>
        <span class="n">artifact_path</span><span class="o">=</span><span class="s2">&quot;ridge_classifier_pipeline&quot;</span><span class="p">,</span>
        <span class="n">registered_model_name</span><span class="o">=</span><span class="s2">&quot;RidgeClassifierPipeline&quot;</span><span class="p">,</span>
        <span class="n">input_example</span><span class="o">=</span><span class="n">input_example</span>  <span class="c1"># Include input example to remove warnings</span>
    <span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Ridge Classifier Experiment Logged Successfully!&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\Vanu\anaconda3\Lib\site-packages\mlflow\types\utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values &lt;https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values&gt;`_ for more details.
  warnings.warn(
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "ec9524e1a6954974a87d2401bd7486c4", "version_major": 2, "version_minor": 0}</script><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Registered model &#39;RidgeClassifierPipeline&#39; already exists. Creating a new version of this model...
2024/12/19 19:06:44 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: RidgeClassifierPipeline, version 4
Created version &#39;4&#39; of model &#39;RidgeClassifierPipeline&#39;.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>ðŸƒ View run Ridge Classifier Run at: https://dagshub.com/ryallavinuthnareddy/VINUTHNA_PYTHON_ML_PROJECT.mlflow/#/experiments/9/runs/c3574d9c73574864a5a834b9fe220ebd
ðŸ§ª View experiment at: https://dagshub.com/ryallavinuthnareddy/VINUTHNA_PYTHON_ML_PROJECT.mlflow/#/experiments/9
Ridge Classifier Experiment Logged Successfully!
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">ColumnTransformer</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">MinMaxScaler</span><span class="p">,</span> <span class="n">FunctionTransformer</span><span class="p">,</span> <span class="n">OneHotEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">confusion_matrix</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mlflow</span>
<span class="kn">import</span> <span class="nn">mlflow.sklearn</span>

<span class="c1"># Random Forest Classifier</span>
<span class="n">random_forest</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;preprocessor&#39;</span><span class="p">,</span> <span class="n">preprocessor</span><span class="p">),</span>
    <span class="p">(</span><span class="s1">&#39;classifier&#39;</span><span class="p">,</span> <span class="n">random_forest</span><span class="p">)</span>
<span class="p">])</span>

<span class="c1"># Cross-validation</span>
<span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1_weighted&#39;</span><span class="p">)</span>
<span class="n">mean_cv_f1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">)</span>
<span class="n">std_cv_f1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">)</span>

<span class="c1"># Train and evaluate</span>
<span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_train_pred</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">train_f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;weighted&quot;</span><span class="p">)</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred</span><span class="p">)</span>
<span class="n">conf_matrix</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred</span><span class="p">)</span>

<span class="c1"># Compute TP, TN, FP, FN for multi-class</span>
<span class="k">def</span> <span class="nf">calculate_tp_tn_fp_fn</span><span class="p">(</span><span class="n">confusion_mat</span><span class="p">,</span> <span class="n">class_idx</span><span class="p">):</span>
    <span class="n">TP</span> <span class="o">=</span> <span class="n">confusion_mat</span><span class="p">[</span><span class="n">class_idx</span><span class="p">,</span> <span class="n">class_idx</span><span class="p">]</span>
    <span class="n">FP</span> <span class="o">=</span> <span class="n">confusion_mat</span><span class="p">[:,</span> <span class="n">class_idx</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="n">TP</span>
    <span class="n">FN</span> <span class="o">=</span> <span class="n">confusion_mat</span><span class="p">[</span><span class="n">class_idx</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="n">TP</span>
    <span class="n">TN</span> <span class="o">=</span> <span class="n">confusion_mat</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="p">(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">FP</span> <span class="o">+</span> <span class="n">FN</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">TP</span><span class="p">,</span> <span class="n">TN</span><span class="p">,</span> <span class="n">FP</span><span class="p">,</span> <span class="n">FN</span>

<span class="c1"># Example input row from the training data</span>
<span class="n">input_example</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># First row of X_train</span>

<span class="c1"># Log results to MLFlow</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_experiment</span><span class="p">(</span><span class="s2">&quot;Random Forest Experiment&quot;</span><span class="p">)</span>

<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">(</span><span class="n">run_name</span><span class="o">=</span><span class="s2">&quot;Random Forest Run&quot;</span><span class="p">):</span>
    <span class="c1"># Log parameters</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_param</span><span class="p">(</span><span class="s2">&quot;model_name&quot;</span><span class="p">,</span> <span class="s2">&quot;Random Forest Classifier&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">random_forest</span><span class="p">,</span> <span class="s2">&quot;get_params&quot;</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">param</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">random_forest</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">mlflow</span><span class="o">.</span><span class="n">log_param</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
    
    <span class="c1"># Log metrics</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;mean_cv_f1&quot;</span><span class="p">,</span> <span class="n">mean_cv_f1</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;std_cv_f1&quot;</span><span class="p">,</span> <span class="n">std_cv_f1</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;train_f1&quot;</span><span class="p">,</span> <span class="n">train_f1</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
    
    <span class="c1"># Log TP, TN, FP, FN for each class</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">class_name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_train</span><span class="p">)):</span>  <span class="c1"># Class labels</span>
        <span class="n">TP</span><span class="p">,</span> <span class="n">TN</span><span class="p">,</span> <span class="n">FP</span><span class="p">,</span> <span class="n">FN</span> <span class="o">=</span> <span class="n">calculate_tp_tn_fp_fn</span><span class="p">(</span><span class="n">conf_matrix</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TP_Class_</span><span class="si">{</span><span class="n">class_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">TP</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TN_Class_</span><span class="si">{</span><span class="n">class_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">TN</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;FP_Class_</span><span class="si">{</span><span class="n">class_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">FP</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;FN_Class_</span><span class="si">{</span><span class="n">class_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">FN</span><span class="p">)</span>
    
    <span class="c1"># Log confusion matrix as artifact</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_dict</span><span class="p">({</span><span class="s2">&quot;confusion_matrix&quot;</span><span class="p">:</span> <span class="n">conf_matrix</span><span class="o">.</span><span class="n">tolist</span><span class="p">()},</span> <span class="s2">&quot;confusion_matrix.json&quot;</span><span class="p">)</span>
    
    <span class="c1"># Log model with input example</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">sklearn</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span>
        <span class="n">sk_model</span><span class="o">=</span><span class="n">pipeline</span><span class="p">,</span>
        <span class="n">artifact_path</span><span class="o">=</span><span class="s2">&quot;RandomForestPipeline&quot;</span><span class="p">,</span>
        <span class="n">registered_model_name</span><span class="o">=</span><span class="s2">&quot;RandomForestPipeline&quot;</span><span class="p">,</span>
        <span class="n">input_example</span><span class="o">=</span><span class="n">input_example</span>  <span class="c1"># Include input example to remove warnings</span>
    <span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Random Forest Experiment Logged Successfully!&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\Vanu\anaconda3\Lib\site-packages\mlflow\types\utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values &lt;https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values&gt;`_ for more details.
  warnings.warn(
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "05da3177420b4dc298f2cb2e1a3ce942", "version_major": 2, "version_minor": 0}</script><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Registered model &#39;RandomForestPipeline&#39; already exists. Creating a new version of this model...
2024/12/19 19:07:35 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: RandomForestPipeline, version 5
Created version &#39;5&#39; of model &#39;RandomForestPipeline&#39;.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>ðŸƒ View run Random Forest Run at: https://dagshub.com/ryallavinuthnareddy/VINUTHNA_PYTHON_ML_PROJECT.mlflow/#/experiments/10/runs/905eba0b752048d18123cbc4d1228368
ðŸ§ª View experiment at: https://dagshub.com/ryallavinuthnareddy/VINUTHNA_PYTHON_ML_PROJECT.mlflow/#/experiments/10
Random Forest Experiment Logged Successfully!
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">xgboost</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Collecting xgboost
  Obtaining dependency information for xgboost from https://files.pythonhosted.org/packages/70/58/2f94976df39470fb00eec2cb4f914dde44cd0df8d96483208bf7db4bc97e/xgboost-2.1.3-py3-none-win_amd64.whl.metadata
  Downloading xgboost-2.1.3-py3-none-win_amd64.whl.metadata (2.1 kB)
Requirement already satisfied: numpy in c:\users\vanu\anaconda3\lib\site-packages (from xgboost) (1.24.3)
Requirement already satisfied: scipy in c:\users\vanu\anaconda3\lib\site-packages (from xgboost) (1.11.1)
Downloading xgboost-2.1.3-py3-none-win_amd64.whl (124.9 MB)
   ---------------------------------------- 0.0/124.9 MB ? eta -:--:--
   ---------------------------------------- 0.0/124.9 MB 682.7 kB/s eta 0:03:03
   ---------------------------------------- 0.1/124.9 MB 825.8 kB/s eta 0:02:32
   ---------------------------------------- 0.2/124.9 MB 1.7 MB/s eta 0:01:14
   ---------------------------------------- 0.2/124.9 MB 1.7 MB/s eta 0:01:14
   ---------------------------------------- 0.2/124.9 MB 1.7 MB/s eta 0:01:14
   ---------------------------------------- 0.3/124.9 MB 983.0 kB/s eta 0:02:07
   ---------------------------------------- 0.4/124.9 MB 1.3 MB/s eta 0:01:36
   ---------------------------------------- 0.5/124.9 MB 1.6 MB/s eta 0:01:20
   ---------------------------------------- 0.5/124.9 MB 1.6 MB/s eta 0:01:20
   ---------------------------------------- 0.5/124.9 MB 1.2 MB/s eta 0:01:45
   ---------------------------------------- 0.6/124.9 MB 1.3 MB/s eta 0:01:37
   ---------------------------------------- 0.7/124.9 MB 1.3 MB/s eta 0:01:35
   ---------------------------------------- 0.7/124.9 MB 1.2 MB/s eta 0:01:45
   ---------------------------------------- 0.8/124.9 MB 1.3 MB/s eta 0:01:35
   ---------------------------------------- 0.9/124.9 MB 1.3 MB/s eta 0:01:34
   ---------------------------------------- 0.9/124.9 MB 1.3 MB/s eta 0:01:34
   ---------------------------------------- 1.0/124.9 MB 1.3 MB/s eta 0:01:37
   ---------------------------------------- 1.1/124.9 MB 1.4 MB/s eta 0:01:31
   ---------------------------------------- 1.1/124.9 MB 1.4 MB/s eta 0:01:31
   ---------------------------------------- 1.2/124.9 MB 1.3 MB/s eta 0:01:37
   ---------------------------------------- 1.2/124.9 MB 1.3 MB/s eta 0:01:36
   ---------------------------------------- 1.3/124.9 MB 1.3 MB/s eta 0:01:39
   ---------------------------------------- 1.3/124.9 MB 1.3 MB/s eta 0:01:39
   ---------------------------------------- 1.5/124.9 MB 1.4 MB/s eta 0:01:31
   ---------------------------------------- 1.5/124.9 MB 1.4 MB/s eta 0:01:29
    --------------------------------------- 1.8/124.9 MB 1.5 MB/s eta 0:01:22
    --------------------------------------- 1.9/124.9 MB 1.6 MB/s eta 0:01:19
    --------------------------------------- 2.0/124.9 MB 1.6 MB/s eta 0:01:18
    --------------------------------------- 2.1/124.9 MB 1.6 MB/s eta 0:01:15
    --------------------------------------- 2.3/124.9 MB 1.7 MB/s eta 0:01:13
    --------------------------------------- 2.4/124.9 MB 1.7 MB/s eta 0:01:13
    --------------------------------------- 2.6/124.9 MB 1.8 MB/s eta 0:01:09
    --------------------------------------- 2.7/124.9 MB 1.8 MB/s eta 0:01:10
    --------------------------------------- 2.8/124.9 MB 1.9 MB/s eta 0:01:06
    --------------------------------------- 3.1/124.9 MB 1.9 MB/s eta 0:01:03
   - -------------------------------------- 3.3/124.9 MB 2.0 MB/s eta 0:01:02
   - -------------------------------------- 3.4/124.9 MB 2.0 MB/s eta 0:01:02
   - -------------------------------------- 3.6/124.9 MB 2.1 MB/s eta 0:00:59
   - -------------------------------------- 3.8/124.9 MB 2.1 MB/s eta 0:00:58
   - -------------------------------------- 4.0/124.9 MB 2.2 MB/s eta 0:00:56
   - -------------------------------------- 4.3/124.9 MB 2.3 MB/s eta 0:00:53
   - -------------------------------------- 4.5/124.9 MB 2.3 MB/s eta 0:00:52
   - -------------------------------------- 4.6/124.9 MB 2.4 MB/s eta 0:00:51
   - -------------------------------------- 4.9/124.9 MB 2.4 MB/s eta 0:00:50
   - -------------------------------------- 5.0/124.9 MB 2.4 MB/s eta 0:00:50
   - -------------------------------------- 5.5/124.9 MB 2.6 MB/s eta 0:00:46
   - -------------------------------------- 5.9/124.9 MB 2.7 MB/s eta 0:00:44
   -- ------------------------------------- 6.3/124.9 MB 2.9 MB/s eta 0:00:41
   -- ------------------------------------- 6.5/124.9 MB 2.9 MB/s eta 0:00:42
   -- ------------------------------------- 7.0/124.9 MB 3.1 MB/s eta 0:00:39
   -- ------------------------------------- 7.5/124.9 MB 3.2 MB/s eta 0:00:37
   -- ------------------------------------- 8.1/124.9 MB 3.4 MB/s eta 0:00:35
   -- ------------------------------------- 8.2/124.9 MB 3.4 MB/s eta 0:00:35
   -- ------------------------------------- 8.6/124.9 MB 3.5 MB/s eta 0:00:34
   -- ------------------------------------- 9.2/124.9 MB 3.7 MB/s eta 0:00:32
   --- ------------------------------------ 9.6/124.9 MB 3.8 MB/s eta 0:00:31
   --- ------------------------------------ 10.3/124.9 MB 4.0 MB/s eta 0:00:29
   --- ------------------------------------ 10.8/124.9 MB 4.6 MB/s eta 0:00:25
   --- ------------------------------------ 11.4/124.9 MB 5.6 MB/s eta 0:00:21
   --- ------------------------------------ 12.3/124.9 MB 7.0 MB/s eta 0:00:16
   ---- ----------------------------------- 13.2/124.9 MB 8.3 MB/s eta 0:00:14
   ---- ----------------------------------- 14.0/124.9 MB 9.6 MB/s eta 0:00:12
   ---- ----------------------------------- 14.7/124.9 MB 10.6 MB/s eta 0:00:11
   ---- ----------------------------------- 14.9/124.9 MB 11.1 MB/s eta 0:00:10
   ---- ----------------------------------- 15.6/124.9 MB 11.5 MB/s eta 0:00:10
   ----- ---------------------------------- 16.1/124.9 MB 11.9 MB/s eta 0:00:10
   ----- ---------------------------------- 16.5/124.9 MB 11.5 MB/s eta 0:00:10
   ----- ---------------------------------- 17.1/124.9 MB 12.4 MB/s eta 0:00:09
   ----- ---------------------------------- 17.8/124.9 MB 12.4 MB/s eta 0:00:09
   ----- ---------------------------------- 18.2/124.9 MB 12.6 MB/s eta 0:00:09
   ----- ---------------------------------- 18.6/124.9 MB 12.6 MB/s eta 0:00:09
   ------ --------------------------------- 19.5/124.9 MB 13.6 MB/s eta 0:00:08
   ------ --------------------------------- 20.2/124.9 MB 13.4 MB/s eta 0:00:08
   ------ --------------------------------- 21.0/124.9 MB 13.9 MB/s eta 0:00:08
   ------ --------------------------------- 21.7/124.9 MB 13.9 MB/s eta 0:00:08
   ------- -------------------------------- 22.7/124.9 MB 14.2 MB/s eta 0:00:08
   ------- -------------------------------- 24.0/124.9 MB 14.2 MB/s eta 0:00:08
   ------- -------------------------------- 24.1/124.9 MB 13.6 MB/s eta 0:00:08
   -------- ------------------------------- 25.4/124.9 MB 15.6 MB/s eta 0:00:07
   -------- ------------------------------- 26.1/124.9 MB 14.9 MB/s eta 0:00:07
   -------- ------------------------------- 27.0/124.9 MB 16.4 MB/s eta 0:00:06
   -------- ------------------------------- 27.1/124.9 MB 14.9 MB/s eta 0:00:07
   --------- ------------------------------ 28.4/124.9 MB 16.0 MB/s eta 0:00:07
   --------- ------------------------------ 29.5/124.9 MB 17.2 MB/s eta 0:00:06
   --------- ------------------------------ 30.2/124.9 MB 18.2 MB/s eta 0:00:06
   --------- ------------------------------ 30.8/124.9 MB 17.2 MB/s eta 0:00:06
   ---------- ----------------------------- 31.5/124.9 MB 17.3 MB/s eta 0:00:06
   ---------- ----------------------------- 32.3/124.9 MB 17.2 MB/s eta 0:00:06
   ---------- ----------------------------- 33.3/124.9 MB 18.2 MB/s eta 0:00:06
   ---------- ----------------------------- 34.3/124.9 MB 18.7 MB/s eta 0:00:05
   ----------- ---------------------------- 34.9/124.9 MB 17.7 MB/s eta 0:00:06
   ----------- ---------------------------- 35.7/124.9 MB 17.2 MB/s eta 0:00:06
   ----------- ---------------------------- 36.3/124.9 MB 17.2 MB/s eta 0:00:06
   ----------- ---------------------------- 37.0/124.9 MB 16.8 MB/s eta 0:00:06
   ----------- ---------------------------- 37.3/124.9 MB 17.2 MB/s eta 0:00:06
   ------------ --------------------------- 38.4/124.9 MB 16.8 MB/s eta 0:00:06
   ------------ --------------------------- 39.1/124.9 MB 16.4 MB/s eta 0:00:06
   ------------ --------------------------- 39.9/124.9 MB 16.0 MB/s eta 0:00:06
   ------------- -------------------------- 40.6/124.9 MB 16.4 MB/s eta 0:00:06
   ------------- -------------------------- 41.6/124.9 MB 16.8 MB/s eta 0:00:05
   ------------- -------------------------- 42.4/124.9 MB 16.8 MB/s eta 0:00:05
   -------------- ------------------------- 43.8/124.9 MB 17.2 MB/s eta 0:00:05
   -------------- ------------------------- 44.8/124.9 MB 17.7 MB/s eta 0:00:05
   -------------- ------------------------- 46.0/124.9 MB 18.7 MB/s eta 0:00:05
   --------------- ------------------------ 46.9/124.9 MB 19.2 MB/s eta 0:00:05
   --------------- ------------------------ 47.9/124.9 MB 20.5 MB/s eta 0:00:04
   --------------- ------------------------ 48.9/124.9 MB 20.5 MB/s eta 0:00:04
   --------------- ------------------------ 49.8/124.9 MB 21.1 MB/s eta 0:00:04
   ---------------- ----------------------- 50.6/124.9 MB 21.1 MB/s eta 0:00:04
   ---------------- ----------------------- 51.6/124.9 MB 21.9 MB/s eta 0:00:04
   ---------------- ----------------------- 52.4/124.9 MB 21.1 MB/s eta 0:00:04
   ----------------- ---------------------- 53.4/124.9 MB 21.8 MB/s eta 0:00:04
   ----------------- ---------------------- 54.4/124.9 MB 20.5 MB/s eta 0:00:04
   ----------------- ---------------------- 55.5/124.9 MB 20.5 MB/s eta 0:00:04
   ------------------ --------------------- 56.6/124.9 MB 21.1 MB/s eta 0:00:04
   ------------------ --------------------- 57.9/124.9 MB 21.1 MB/s eta 0:00:04
   ------------------ --------------------- 59.1/124.9 MB 21.8 MB/s eta 0:00:04
   ------------------- -------------------- 59.8/124.9 MB 21.9 MB/s eta 0:00:03
   ------------------- -------------------- 60.9/124.9 MB 21.8 MB/s eta 0:00:03
   ------------------- -------------------- 62.2/124.9 MB 22.6 MB/s eta 0:00:03
   -------------------- ------------------- 63.3/124.9 MB 23.4 MB/s eta 0:00:03
   -------------------- ------------------- 64.4/124.9 MB 23.4 MB/s eta 0:00:03
   --------------------- ------------------ 65.6/124.9 MB 24.2 MB/s eta 0:00:03
   --------------------- ------------------ 66.8/124.9 MB 23.4 MB/s eta 0:00:03
   --------------------- ------------------ 67.9/124.9 MB 24.3 MB/s eta 0:00:03
   ---------------------- ----------------- 69.1/124.9 MB 23.4 MB/s eta 0:00:03
   ---------------------- ----------------- 70.4/124.9 MB 25.2 MB/s eta 0:00:03
   ---------------------- ----------------- 71.1/124.9 MB 23.4 MB/s eta 0:00:03
   ---------------------- ----------------- 71.6/124.9 MB 21.8 MB/s eta 0:00:03
   ----------------------- ---------------- 72.3/124.9 MB 21.1 MB/s eta 0:00:03
   ----------------------- ---------------- 72.9/124.9 MB 20.5 MB/s eta 0:00:03
   ----------------------- ---------------- 73.9/124.9 MB 20.5 MB/s eta 0:00:03
   ----------------------- ---------------- 74.1/124.9 MB 19.3 MB/s eta 0:00:03
   ----------------------- ---------------- 74.6/124.9 MB 18.2 MB/s eta 0:00:03
   ------------------------ --------------- 75.2/124.9 MB 18.2 MB/s eta 0:00:03
   ------------------------ --------------- 76.1/124.9 MB 17.2 MB/s eta 0:00:03
   ------------------------ --------------- 77.0/124.9 MB 16.8 MB/s eta 0:00:03
   ------------------------ --------------- 77.8/124.9 MB 16.8 MB/s eta 0:00:03
   ------------------------- -------------- 78.5/124.9 MB 16.4 MB/s eta 0:00:03
   ------------------------- -------------- 79.7/124.9 MB 16.4 MB/s eta 0:00:03
   ------------------------- -------------- 80.7/124.9 MB 16.8 MB/s eta 0:00:03
   -------------------------- ------------- 81.6/124.9 MB 16.8 MB/s eta 0:00:03
   -------------------------- ------------- 82.5/124.9 MB 16.8 MB/s eta 0:00:03
   -------------------------- ------------- 83.7/124.9 MB 17.7 MB/s eta 0:00:03
   --------------------------- ------------ 84.7/124.9 MB 19.8 MB/s eta 0:00:03
   --------------------------- ------------ 86.1/124.9 MB 21.1 MB/s eta 0:00:02
   --------------------------- ------------ 87.4/124.9 MB 23.4 MB/s eta 0:00:02
   ---------------------------- ----------- 88.1/124.9 MB 22.5 MB/s eta 0:00:02
   ---------------------------- ----------- 89.7/124.9 MB 24.3 MB/s eta 0:00:02
   ----------------------------- ---------- 91.7/124.9 MB 26.2 MB/s eta 0:00:02
   ----------------------------- ---------- 92.1/124.9 MB 28.5 MB/s eta 0:00:02
   ----------------------------- ---------- 93.4/124.9 MB 27.3 MB/s eta 0:00:02
   ------------------------------ --------- 95.1/124.9 MB 28.5 MB/s eta 0:00:02
   ------------------------------ --------- 96.3/124.9 MB 28.5 MB/s eta 0:00:02
   ------------------------------- -------- 97.0/124.9 MB 25.1 MB/s eta 0:00:02
   ------------------------------- -------- 98.7/124.9 MB 28.4 MB/s eta 0:00:01
   ------------------------------- ------- 100.5/124.9 MB 28.5 MB/s eta 0:00:01
   ------------------------------- ------- 100.5/124.9 MB 28.5 MB/s eta 0:00:01
   ------------------------------- ------- 101.9/124.9 MB 24.2 MB/s eta 0:00:01
   -------------------------------- ------ 103.0/124.9 MB 26.2 MB/s eta 0:00:01
   -------------------------------- ------ 104.7/124.9 MB 26.2 MB/s eta 0:00:01
   -------------------------------- ------ 105.4/124.9 MB 24.3 MB/s eta 0:00:01
   --------------------------------- ----- 107.2/124.9 MB 26.2 MB/s eta 0:00:01
   --------------------------------- ----- 108.1/124.9 MB 25.2 MB/s eta 0:00:01
   ---------------------------------- ---- 109.2/124.9 MB 25.2 MB/s eta 0:00:01
   ---------------------------------- ---- 110.6/124.9 MB 23.4 MB/s eta 0:00:01
   ---------------------------------- ---- 111.4/124.9 MB 26.2 MB/s eta 0:00:01
   ---------------------------------- ---- 111.7/124.9 MB 23.4 MB/s eta 0:00:01
   ----------------------------------- --- 112.7/124.9 MB 22.5 MB/s eta 0:00:01
   ----------------------------------- --- 113.3/124.9 MB 21.8 MB/s eta 0:00:01
   ----------------------------------- --- 114.3/124.9 MB 21.1 MB/s eta 0:00:01
   ----------------------------------- --- 114.8/124.9 MB 19.3 MB/s eta 0:00:01
   ------------------------------------ -- 115.8/124.9 MB 20.5 MB/s eta 0:00:01
   ------------------------------------ -- 116.4/124.9 MB 19.8 MB/s eta 0:00:01
   ------------------------------------ -- 117.5/124.9 MB 19.3 MB/s eta 0:00:01
   ------------------------------------- - 118.6/124.9 MB 18.7 MB/s eta 0:00:01
   ------------------------------------- - 119.6/124.9 MB 18.7 MB/s eta 0:00:01
   ------------------------------------- - 120.5/124.9 MB 18.2 MB/s eta 0:00:01
   ------------------------------------- - 121.3/124.9 MB 17.7 MB/s eta 0:00:01
   --------------------------------------  121.8/124.9 MB 18.2 MB/s eta 0:00:01
   --------------------------------------  123.1/124.9 MB 18.7 MB/s eta 0:00:01
   --------------------------------------  124.0/124.9 MB 19.3 MB/s eta 0:00:01
   --------------------------------------  124.9/124.9 MB 19.9 MB/s eta 0:00:01
   --------------------------------------  124.9/124.9 MB 19.9 MB/s eta 0:00:01
   --------------------------------------  124.9/124.9 MB 19.9 MB/s eta 0:00:01
   --------------------------------------  124.9/124.9 MB 19.9 MB/s eta 0:00:01
   --------------------------------------  124.9/124.9 MB 19.9 MB/s eta 0:00:01
   --------------------------------------  124.9/124.9 MB 19.9 MB/s eta 0:00:01
   --------------------------------------  124.9/124.9 MB 19.9 MB/s eta 0:00:01
   --------------------------------------  124.9/124.9 MB 19.9 MB/s eta 0:00:01
   --------------------------------------  124.9/124.9 MB 19.9 MB/s eta 0:00:01
   --------------------------------------  124.9/124.9 MB 19.9 MB/s eta 0:00:01
   --------------------------------------  124.9/124.9 MB 19.9 MB/s eta 0:00:01
   --------------------------------------  124.9/124.9 MB 19.9 MB/s eta 0:00:01
   --------------------------------------  124.9/124.9 MB 19.9 MB/s eta 0:00:01
   --------------------------------------  124.9/124.9 MB 19.9 MB/s eta 0:00:01
   --------------------------------------  124.9/124.9 MB 19.9 MB/s eta 0:00:01
   --------------------------------------  124.9/124.9 MB 19.9 MB/s eta 0:00:01
   --------------------------------------  124.9/124.9 MB 19.9 MB/s eta 0:00:01
   --------------------------------------  124.9/124.9 MB 19.9 MB/s eta 0:00:01
   --------------------------------------  124.9/124.9 MB 19.9 MB/s eta 0:00:01
   --------------------------------------  124.9/124.9 MB 19.9 MB/s eta 0:00:01
   --------------------------------------  124.9/124.9 MB 19.9 MB/s eta 0:00:01
   --------------------------------------  124.9/124.9 MB 19.9 MB/s eta 0:00:01
   --------------------------------------  124.9/124.9 MB 19.9 MB/s eta 0:00:01
   --------------------------------------  124.9/124.9 MB 19.9 MB/s eta 0:00:01
   --------------------------------------  124.9/124.9 MB 19.9 MB/s eta 0:00:01
   --------------------------------------  124.9/124.9 MB 19.9 MB/s eta 0:00:01
   --------------------------------------  124.9/124.9 MB 19.9 MB/s eta 0:00:01
   --------------------------------------  124.9/124.9 MB 19.9 MB/s eta 0:00:01
   --------------------------------------  124.9/124.9 MB 19.9 MB/s eta 0:00:01
   --------------------------------------  124.9/124.9 MB 19.9 MB/s eta 0:00:01
   --------------------------------------  124.9/124.9 MB 19.9 MB/s eta 0:00:01
   --------------------------------------  124.9/124.9 MB 19.9 MB/s eta 0:00:01
   ---------------------------------------- 124.9/124.9 MB 4.8 MB/s eta 0:00:00
Installing collected packages: xgboost
Successfully installed xgboost-2.1.3
Note: you may need to restart the kernel to use updated packages.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">XGBClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">ColumnTransformer</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">MinMaxScaler</span><span class="p">,</span> <span class="n">FunctionTransformer</span><span class="p">,</span> <span class="n">OneHotEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">confusion_matrix</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mlflow</span>
<span class="kn">import</span> <span class="nn">mlflow.sklearn</span>

<span class="c1"># XGBoost Classifier</span>
<span class="n">xgb</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span><span class="n">use_label_encoder</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">eval_metric</span><span class="o">=</span><span class="s2">&quot;mlogloss&quot;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;preprocessor&#39;</span><span class="p">,</span> <span class="n">preprocessor</span><span class="p">),</span>
    <span class="p">(</span><span class="s1">&#39;classifier&#39;</span><span class="p">,</span> <span class="n">xgb</span><span class="p">)</span>
<span class="p">])</span>

<span class="c1"># Cross-validation</span>
<span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1_weighted&#39;</span><span class="p">)</span>
<span class="n">mean_cv_f1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">)</span>
<span class="n">std_cv_f1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">)</span>

<span class="c1"># Train and evaluate</span>
<span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_train_pred</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">train_f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;weighted&quot;</span><span class="p">)</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred</span><span class="p">)</span>
<span class="n">conf_matrix</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred</span><span class="p">)</span>

<span class="c1"># Compute TP, TN, FP, FN for multi-class</span>
<span class="k">def</span> <span class="nf">calculate_tp_tn_fp_fn</span><span class="p">(</span><span class="n">confusion_mat</span><span class="p">,</span> <span class="n">class_idx</span><span class="p">):</span>
    <span class="n">TP</span> <span class="o">=</span> <span class="n">confusion_mat</span><span class="p">[</span><span class="n">class_idx</span><span class="p">,</span> <span class="n">class_idx</span><span class="p">]</span>
    <span class="n">FP</span> <span class="o">=</span> <span class="n">confusion_mat</span><span class="p">[:,</span> <span class="n">class_idx</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="n">TP</span>
    <span class="n">FN</span> <span class="o">=</span> <span class="n">confusion_mat</span><span class="p">[</span><span class="n">class_idx</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="n">TP</span>
    <span class="n">TN</span> <span class="o">=</span> <span class="n">confusion_mat</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="p">(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">FP</span> <span class="o">+</span> <span class="n">FN</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">TP</span><span class="p">,</span> <span class="n">TN</span><span class="p">,</span> <span class="n">FP</span><span class="p">,</span> <span class="n">FN</span>

<span class="c1"># Example input row from the training data</span>
<span class="n">input_example</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># First row of X_train</span>

<span class="c1"># Log results to MLFlow</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_experiment</span><span class="p">(</span><span class="s2">&quot;XGBoost Experiment&quot;</span><span class="p">)</span>

<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">(</span><span class="n">run_name</span><span class="o">=</span><span class="s2">&quot;XGBoost Run&quot;</span><span class="p">):</span>
    <span class="c1"># Log parameters</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_param</span><span class="p">(</span><span class="s2">&quot;model_name&quot;</span><span class="p">,</span> <span class="s2">&quot;XGBoost Classifier&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">xgb</span><span class="p">,</span> <span class="s2">&quot;get_params&quot;</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">param</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">xgb</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">mlflow</span><span class="o">.</span><span class="n">log_param</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
    
    <span class="c1"># Log metrics</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;mean_cv_f1&quot;</span><span class="p">,</span> <span class="n">mean_cv_f1</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;std_cv_f1&quot;</span><span class="p">,</span> <span class="n">std_cv_f1</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;train_f1&quot;</span><span class="p">,</span> <span class="n">train_f1</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
    
    <span class="c1"># Log TP, TN, FP, FN for each class</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">class_name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_train</span><span class="p">)):</span>  <span class="c1"># Class labels</span>
        <span class="n">TP</span><span class="p">,</span> <span class="n">TN</span><span class="p">,</span> <span class="n">FP</span><span class="p">,</span> <span class="n">FN</span> <span class="o">=</span> <span class="n">calculate_tp_tn_fp_fn</span><span class="p">(</span><span class="n">conf_matrix</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TP_Class_</span><span class="si">{</span><span class="n">class_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">TP</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TN_Class_</span><span class="si">{</span><span class="n">class_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">TN</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;FP_Class_</span><span class="si">{</span><span class="n">class_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">FP</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;FN_Class_</span><span class="si">{</span><span class="n">class_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">FN</span><span class="p">)</span>
    
    <span class="c1"># Log confusion matrix as artifact</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_dict</span><span class="p">({</span><span class="s2">&quot;confusion_matrix&quot;</span><span class="p">:</span> <span class="n">conf_matrix</span><span class="o">.</span><span class="n">tolist</span><span class="p">()},</span> <span class="s2">&quot;confusion_matrix.json&quot;</span><span class="p">)</span>
    
    <span class="c1"># Log model with input example</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">sklearn</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span>
        <span class="n">sk_model</span><span class="o">=</span><span class="n">pipeline</span><span class="p">,</span>
        <span class="n">artifact_path</span><span class="o">=</span><span class="s2">&quot;XGBoostPipeline&quot;</span><span class="p">,</span>
        <span class="n">registered_model_name</span><span class="o">=</span><span class="s2">&quot;XGBoostPipeline&quot;</span><span class="p">,</span>
        <span class="n">input_example</span><span class="o">=</span><span class="n">input_example</span>  <span class="c1"># Include input example to remove warnings</span>
    <span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;XGBoost Experiment Logged Successfully!&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\Vanu\anaconda3\Lib\site-packages\xgboost\core.py:158: UserWarning: [19:10:15] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { &quot;use_label_encoder&quot; } are not used.

  warnings.warn(smsg, UserWarning)
C:\Users\Vanu\anaconda3\Lib\site-packages\xgboost\core.py:158: UserWarning: [19:10:15] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { &quot;use_label_encoder&quot; } are not used.

  warnings.warn(smsg, UserWarning)
C:\Users\Vanu\anaconda3\Lib\site-packages\xgboost\core.py:158: UserWarning: [19:10:15] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { &quot;use_label_encoder&quot; } are not used.

  warnings.warn(smsg, UserWarning)
C:\Users\Vanu\anaconda3\Lib\site-packages\xgboost\core.py:158: UserWarning: [19:10:15] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { &quot;use_label_encoder&quot; } are not used.

  warnings.warn(smsg, UserWarning)
2024/12/19 19:10:16 INFO mlflow.tracking.fluent: Experiment with name &#39;XGBoost Experiment&#39; does not exist. Creating a new experiment.
C:\Users\Vanu\anaconda3\Lib\site-packages\mlflow\types\utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values &lt;https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values&gt;`_ for more details.
  warnings.warn(
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "ebf5d0538bae4a0e9657152eaae5b76b", "version_major": 2, "version_minor": 0}</script><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Successfully registered model &#39;XGBoostPipeline&#39;.
2024/12/19 19:11:16 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: XGBoostPipeline, version 1
Created version &#39;1&#39; of model &#39;XGBoostPipeline&#39;.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>ðŸƒ View run XGBoost Run at: https://dagshub.com/ryallavinuthnareddy/VINUTHNA_PYTHON_ML_PROJECT.mlflow/#/experiments/11/runs/8b7a63d6446e4b599c5d0b2e890b67b6
ðŸ§ª View experiment at: https://dagshub.com/ryallavinuthnareddy/VINUTHNA_PYTHON_ML_PROJECT.mlflow/#/experiments/11
XGBoost Experiment Logged Successfully!
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mlflow</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">MinMaxScaler</span><span class="p">,</span> <span class="n">FunctionTransformer</span><span class="p">,</span> <span class="n">PolynomialFeatures</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span><span class="p">,</span> <span class="n">RidgeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">XGBClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">ColumnTransformer</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span>

<span class="c1"># Connect to MLFlow</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_tracking_uri</span><span class="p">(</span><span class="s2">&quot;https://dagshub.com/ryallavinuthnareddy/VINUTHNA_PYTHON_ML_PROJECT.mlflow&quot;</span><span class="p">)</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_experiment</span><span class="p">(</span><span class="s2">&quot;VINUTHNA_PYTHON_ML_PROJECT_EXPERIMENT&quot;</span><span class="p">)</span>

<span class="c1"># Load dataset</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">feature_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;feature_1&quot;</span><span class="p">,</span> <span class="s2">&quot;feature_2&quot;</span><span class="p">,</span> <span class="s2">&quot;feature_3&quot;</span><span class="p">,</span> <span class="s2">&quot;feature_4&quot;</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">feature_names</span><span class="p">)</span>

<span class="c1"># Simulate categorical features (optional for testing OneHotEncoder)</span>
<span class="n">X</span><span class="p">[</span><span class="s1">&#39;CategoricalFeature&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="s1">&#39;C&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">//</span> <span class="mi">3</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">%</span> <span class="mi">3</span><span class="p">)</span>

<span class="c1"># Split data</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># ---- Feature Engineering ----</span>

<span class="c1"># 1. Polynomial Features (Create interaction terms)</span>
<span class="n">poly</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">include_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">X_poly</span> <span class="o">=</span> <span class="n">poly</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">numeric_features</span><span class="p">])</span>

<span class="c1"># 2. Combine features: Create a new feature by adding feature_1 and feature_2</span>
<span class="n">X_train</span><span class="p">[</span><span class="s1">&#39;feature_combination&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="s1">&#39;feature_1&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">X_train</span><span class="p">[</span><span class="s1">&#39;feature_2&#39;</span><span class="p">]</span>

<span class="c1"># 3. Apply Log Transformation on numerical features</span>
<span class="n">log_transformer</span> <span class="o">=</span> <span class="n">FunctionTransformer</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log1p</span><span class="p">,</span> <span class="n">validate</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">X_train_log</span> <span class="o">=</span> <span class="n">log_transformer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">numeric_features</span><span class="p">])</span>

<span class="c1"># ---- Preprocessing Pipeline ----</span>

<span class="c1">#  Define feature groups</span>
<span class="n">numeric_features</span> <span class="o">=</span> <span class="n">feature_names</span>
<span class="n">categorical_features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;CategoricalFeature&#39;</span><span class="p">]</span>

<span class="c1"># Preprocessing pipeline (for original features and engineered features)</span>
<span class="n">preprocessor</span> <span class="o">=</span> <span class="n">ColumnTransformer</span><span class="p">(</span>
    <span class="n">transformers</span><span class="o">=</span><span class="p">[</span>
        <span class="p">(</span><span class="s1">&#39;num&#39;</span><span class="p">,</span> <span class="n">Pipeline</span><span class="p">([</span>
            <span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">,</span> <span class="n">FunctionTransformer</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log1p</span><span class="p">,</span> <span class="n">validate</span><span class="o">=</span><span class="kc">True</span><span class="p">)),</span>  <span class="c1"># Log Transformation</span>
            <span class="p">(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>  <span class="c1"># Standard Scaling</span>
            <span class="p">(</span><span class="s1">&#39;minmax&#39;</span><span class="p">,</span> <span class="n">MinMaxScaler</span><span class="p">())</span>  <span class="c1"># MinMax Scaling</span>
        <span class="p">]),</span> <span class="n">numeric_features</span> <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;feature_combination&quot;</span><span class="p">]),</span>
        <span class="p">(</span><span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="n">OneHotEncoder</span><span class="p">(),</span> <span class="n">categorical_features</span><span class="p">)</span>  <span class="c1"># OneHot Encoding</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="c1"># ---- Model Training ----</span>

<span class="c1"># Define models</span>
<span class="n">log_reg</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;lbfgs&quot;</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s2">&quot;multinomial&quot;</span><span class="p">)</span>
<span class="n">ridge</span> <span class="o">=</span> <span class="n">RidgeClassifier</span><span class="p">()</span>
<span class="n">random_forest</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">xgb</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span><span class="n">use_label_encoder</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">eval_metric</span><span class="o">=</span><span class="s2">&quot;mlogloss&quot;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">models</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;Logistic Regression&quot;</span><span class="p">:</span> <span class="n">log_reg</span><span class="p">,</span>
    <span class="s2">&quot;Ridge Classifier&quot;</span><span class="p">:</span> <span class="n">ridge</span><span class="p">,</span>
    <span class="s2">&quot;Random Forest&quot;</span><span class="p">:</span> <span class="n">random_forest</span><span class="p">,</span>
    <span class="s2">&quot;XGBoost&quot;</span><span class="p">:</span> <span class="n">xgb</span>
<span class="p">}</span>

<span class="c1"># Function for training and evaluating models</span>
<span class="k">def</span> <span class="nf">train_and_evaluate</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">):</span>
    <span class="c1"># Create pipeline</span>
    <span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
        <span class="p">(</span><span class="s1">&#39;preprocessor&#39;</span><span class="p">,</span> <span class="n">preprocessor</span><span class="p">),</span>
        <span class="p">(</span><span class="s1">&#39;classifier&#39;</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
    <span class="p">])</span>

    <span class="c1"># Train the model</span>
    <span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="c1"># Make predictions</span>
    <span class="n">y_train_pred</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

    <span class="c1"># Evaluate the model</span>
    <span class="n">f1_train</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;weighted&quot;</span><span class="p">)</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred</span><span class="p">)</span>

    <span class="c1"># Compute confusion matrix for TP, TN, FP, FN</span>
    <span class="n">conf_matrix</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">class_name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_train</span><span class="p">)):</span>  <span class="c1"># Class labels</span>
        <span class="n">TP</span> <span class="o">=</span> <span class="n">conf_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span>
        <span class="n">TN</span> <span class="o">=</span> <span class="n">conf_matrix</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="p">(</span><span class="n">conf_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">+</span> <span class="n">conf_matrix</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="n">TP</span><span class="p">)</span>
        <span class="n">FP</span> <span class="o">=</span> <span class="n">conf_matrix</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="n">TP</span>
        <span class="n">FN</span> <span class="o">=</span> <span class="n">conf_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="n">TP</span>

        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TP_Class_</span><span class="si">{</span><span class="n">class_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">TP</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TN_Class_</span><span class="si">{</span><span class="n">class_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">TN</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;FP_Class_</span><span class="si">{</span><span class="n">class_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">FP</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;FN_Class_</span><span class="si">{</span><span class="n">class_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">FN</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2"> - Train F1 Score: </span><span class="si">{</span><span class="n">f1_train</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2"> - Accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">f1_train</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">,</span> <span class="n">conf_matrix</span>

<span class="c1"># Log the results in MLFlow</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_experiment</span><span class="p">(</span><span class="s2">&quot;Feature Engineering and Combination Experiment&quot;</span><span class="p">)</span>

<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">(</span><span class="n">run_name</span><span class="o">=</span><span class="s2">&quot;Feature Engineering Run&quot;</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="c1"># Log metrics for each model</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2"> Results:&quot;</span><span class="p">)</span>
        <span class="n">f1</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">,</span> <span class="n">conf_matrix</span> <span class="o">=</span> <span class="n">train_and_evaluate</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

        <span class="c1"># Log metrics</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">_train_f1&quot;</span><span class="p">,</span> <span class="n">f1</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">_train_accuracy&quot;</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>

        <span class="c1"># Log confusion matrix as an artifact</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_dict</span><span class="p">({</span><span class="s2">&quot;confusion_matrix&quot;</span><span class="p">:</span> <span class="n">conf_matrix</span><span class="o">.</span><span class="n">tolist</span><span class="p">()},</span> <span class="sa">f</span><span class="s2">&quot;confusion_matrix_</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">.json&quot;</span><span class="p">)</span>

        <span class="c1"># Log model with input example</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">sklearn</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span>
            <span class="n">sk_model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">artifact_path</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">_pipeline&quot;</span><span class="p">,</span>
            <span class="n">registered_model_name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">Pipeline&quot;</span><span class="p">,</span>
            <span class="n">input_example</span><span class="o">=</span><span class="n">X_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># Log input example to remove warnings</span>
        <span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Model Evaluation and Logging Completed.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Logistic Regression Results:
Logistic Regression - Train F1 Score: 0.8831874087971648
Logistic Regression - Accuracy: 0.8833333333333333
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\Vanu\anaconda3\Lib\site-packages\sklearn\base.py:457: UserWarning: X has feature names, but LogisticRegression was fitted without feature names
  warnings.warn(
2024/12/19 19:40:19 WARNING mlflow.models.signature: Failed to infer the model signature from the input example. Reason: ValueError(&quot;could not convert string to float: &#39;B&#39;&quot;). To see the full traceback, set the logging level to DEBUG via `logging.getLogger(&quot;mlflow&quot;).setLevel(logging.DEBUG)`.
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "76a8f124a6cd4574af0b77373ce7b2fc", "version_major": 2, "version_minor": 0}</script><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\Vanu\anaconda3\Lib\site-packages\sklearn\base.py:457: UserWarning: X has feature names, but LogisticRegression was fitted without feature names
  warnings.warn(
2024/12/19 19:40:23 WARNING mlflow.models.model: Failed to validate serving input example {
  &quot;dataframe_split&quot;: {
    &quot;columns&quot;: [
      &quot;feature_1&quot;,
      &quot;feature_2&quot;,
      &quot;feature_3&quot;,
      &quot;feature_4&quot;,
      &quot;CategoricalFeature&quot;,
      &quot;feature_combination&quot;
    ],
    &quot;data&quot;: [
      [
        4.6,
        3.6,
        1.0,
        0.2,
        &quot;B&quot;,
        8.2
      ]
    ]
  }
}. Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.
Got error: could not convert string to float: &#39;B&#39;
Successfully registered model &#39;Logistic RegressionPipeline&#39;.
2024/12/19 19:40:30 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Logistic RegressionPipeline, version 1
Created version &#39;1&#39; of model &#39;Logistic RegressionPipeline&#39;.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Ridge Classifier Results:
Ridge Classifier - Train F1 Score: 0.8222582687134039
Ridge Classifier - Accuracy: 0.825
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\Vanu\anaconda3\Lib\site-packages\sklearn\base.py:457: UserWarning: X has feature names, but RidgeClassifier was fitted without feature names
  warnings.warn(
2024/12/19 19:40:45 WARNING mlflow.models.signature: Failed to infer the model signature from the input example. Reason: ValueError(&quot;could not convert string to float: &#39;B&#39;&quot;). To see the full traceback, set the logging level to DEBUG via `logging.getLogger(&quot;mlflow&quot;).setLevel(logging.DEBUG)`.
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "cfcf0f63d10a48dbaa157c85d2a80495", "version_major": 2, "version_minor": 0}</script><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\Vanu\anaconda3\Lib\site-packages\sklearn\base.py:457: UserWarning: X has feature names, but RidgeClassifier was fitted without feature names
  warnings.warn(
2024/12/19 19:40:48 WARNING mlflow.models.model: Failed to validate serving input example {
  &quot;dataframe_split&quot;: {
    &quot;columns&quot;: [
      &quot;feature_1&quot;,
      &quot;feature_2&quot;,
      &quot;feature_3&quot;,
      &quot;feature_4&quot;,
      &quot;CategoricalFeature&quot;,
      &quot;feature_combination&quot;
    ],
    &quot;data&quot;: [
      [
        4.6,
        3.6,
        1.0,
        0.2,
        &quot;B&quot;,
        8.2
      ]
    ]
  }
}. Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.
Got error: could not convert string to float: &#39;B&#39;
Successfully registered model &#39;Ridge ClassifierPipeline&#39;.
2024/12/19 19:40:56 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Ridge ClassifierPipeline, version 1
Created version &#39;1&#39; of model &#39;Ridge ClassifierPipeline&#39;.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Random Forest Results:
Random Forest - Train F1 Score: 1.0
Random Forest - Accuracy: 1.0
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\Vanu\anaconda3\Lib\site-packages\sklearn\base.py:457: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names
  warnings.warn(
2024/12/19 19:41:11 WARNING mlflow.models.signature: Failed to infer the model signature from the input example. Reason: ValueError(&quot;could not convert string to float: &#39;B&#39;&quot;). To see the full traceback, set the logging level to DEBUG via `logging.getLogger(&quot;mlflow&quot;).setLevel(logging.DEBUG)`.
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "f6019798877a4a8f8903d26ba1d4bac2", "version_major": 2, "version_minor": 0}</script><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\Vanu\anaconda3\Lib\site-packages\sklearn\base.py:457: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names
  warnings.warn(
2024/12/19 19:41:14 WARNING mlflow.models.model: Failed to validate serving input example {
  &quot;dataframe_split&quot;: {
    &quot;columns&quot;: [
      &quot;feature_1&quot;,
      &quot;feature_2&quot;,
      &quot;feature_3&quot;,
      &quot;feature_4&quot;,
      &quot;CategoricalFeature&quot;,
      &quot;feature_combination&quot;
    ],
    &quot;data&quot;: [
      [
        4.6,
        3.6,
        1.0,
        0.2,
        &quot;B&quot;,
        8.2
      ]
    ]
  }
}. Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.
Got error: could not convert string to float: &#39;B&#39;
Successfully registered model &#39;Random ForestPipeline&#39;.
2024/12/19 19:41:22 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Random ForestPipeline, version 1
Created version &#39;1&#39; of model &#39;Random ForestPipeline&#39;.
C:\Users\Vanu\anaconda3\Lib\site-packages\xgboost\core.py:158: UserWarning: [19:41:22] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { &quot;use_label_encoder&quot; } are not used.

  warnings.warn(smsg, UserWarning)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>XGBoost Results:
XGBoost - Train F1 Score: 1.0
XGBoost - Accuracy: 1.0
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2024/12/19 19:41:37 WARNING mlflow.models.signature: Failed to infer the model signature from the input example. Reason: ValueError(&#39;DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, the experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:CategoricalFeature: object&#39;). To see the full traceback, set the logging level to DEBUG via `logging.getLogger(&quot;mlflow&quot;).setLevel(logging.DEBUG)`.
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "3a06fe5203b74a1dacdc3f8f4b350280", "version_major": 2, "version_minor": 0}</script><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2024/12/19 19:41:44 WARNING mlflow.models.model: Failed to validate serving input example {
  &quot;dataframe_split&quot;: {
    &quot;columns&quot;: [
      &quot;feature_1&quot;,
      &quot;feature_2&quot;,
      &quot;feature_3&quot;,
      &quot;feature_4&quot;,
      &quot;CategoricalFeature&quot;,
      &quot;feature_combination&quot;
    ],
    &quot;data&quot;: [
      [
        4.6,
        3.6,
        1.0,
        0.2,
        &quot;B&quot;,
        8.2
      ]
    ]
  }
}. Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.
Got error: DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, the experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:CategoricalFeature: object
Registered model &#39;XGBoostPipeline&#39; already exists. Creating a new version of this model...
2024/12/19 19:41:49 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: XGBoostPipeline, version 2
Created version &#39;2&#39; of model &#39;XGBoostPipeline&#39;.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>ðŸƒ View run Feature Engineering Run at: https://dagshub.com/ryallavinuthnareddy/VINUTHNA_PYTHON_ML_PROJECT.mlflow/#/experiments/12/runs/c5257377594243528ec6adfb8b3b9045
ðŸ§ª View experiment at: https://dagshub.com/ryallavinuthnareddy/VINUTHNA_PYTHON_ML_PROJECT.mlflow/#/experiments/12
Model Evaluation and Logging Completed.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mlflow</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">VarianceThreshold</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">MinMaxScaler</span><span class="p">,</span> <span class="n">OneHotEncoder</span><span class="p">,</span> <span class="n">FunctionTransformer</span>
<span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">ColumnTransformer</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span><span class="p">,</span> <span class="n">RidgeClassifier</span>
<span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">XGBClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">confusion_matrix</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Connect to MLFlow</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_tracking_uri</span><span class="p">(</span><span class="s2">&quot;https://dagshub.com/ryallavinuthnareddy/VINUTHNA_PYTHON_ML_PROJECT.mlflow&quot;</span><span class="p">)</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_experiment</span><span class="p">(</span><span class="s2">&quot;VINUTHNA_PYTHON_ML_PROJECT_EXPERIMENT&quot;</span><span class="p">)</span>

<span class="c1"># Load dataset</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">feature_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;feature_1&quot;</span><span class="p">,</span> <span class="s2">&quot;feature_2&quot;</span><span class="p">,</span> <span class="s2">&quot;feature_3&quot;</span><span class="p">,</span> <span class="s2">&quot;feature_4&quot;</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">feature_names</span><span class="p">)</span>

<span class="c1"># Train-test split</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># ---- Feature Selection Methods ----</span>

<span class="c1"># 1. **Correlation Threshold**</span>
<span class="k">def</span> <span class="nf">correlation_threshold</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.9</span><span class="p">):</span>
    <span class="n">corr_matrix</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>
    <span class="n">upper_triangle</span> <span class="o">=</span> <span class="n">corr_matrix</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">corr_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">bool</span><span class="p">))</span>
    <span class="n">to_drop</span> <span class="o">=</span> <span class="p">[</span><span class="n">column</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">upper_triangle</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">upper_triangle</span><span class="p">[</span><span class="n">column</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">)]</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Features to drop based on correlation threshold: </span><span class="si">{</span><span class="n">to_drop</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">X_train</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">to_drop</span><span class="p">)</span>

<span class="c1"># Apply Correlation Threshold</span>
<span class="n">X_train_corr_filtered</span> <span class="o">=</span> <span class="n">correlation_threshold</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="c1"># 2. **Feature Importance (Random Forest or XGBoost)**</span>
<span class="k">def</span> <span class="nf">feature_importance</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">importance</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">feature_importances_</span>
    <span class="k">return</span> <span class="n">importance</span>

<span class="c1"># Use Random Forest for feature importance</span>
<span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">importances</span> <span class="o">=</span> <span class="n">feature_importance</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">rf</span><span class="p">)</span>

<span class="c1"># Get important features based on importance threshold</span>
<span class="k">def</span> <span class="nf">filter_important_features</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">importances</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.05</span><span class="p">):</span>
    <span class="n">important_features</span> <span class="o">=</span> <span class="p">[</span><span class="n">feature</span> <span class="k">for</span> <span class="n">feature</span><span class="p">,</span> <span class="n">importance</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">importances</span><span class="p">)</span> <span class="k">if</span> <span class="n">importance</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Important features based on importance threshold: </span><span class="si">{</span><span class="n">important_features</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">X_train</span><span class="p">[</span><span class="n">important_features</span><span class="p">]</span>

<span class="c1"># Apply Feature Importance (filter based on importance threshold)</span>
<span class="n">X_train_important</span> <span class="o">=</span> <span class="n">filter_important_features</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">importances</span><span class="p">)</span>

<span class="c1"># 3. **Variance Threshold**</span>
<span class="k">def</span> <span class="nf">variance_threshold</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
    <span class="n">selector</span> <span class="o">=</span> <span class="n">VarianceThreshold</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">)</span>
    <span class="n">X_train_var_filtered</span> <span class="o">=</span> <span class="n">selector</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_train_var_filtered</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">selector</span><span class="o">.</span><span class="n">get_support</span><span class="p">()])</span>

<span class="c1"># Apply Variance Threshold</span>
<span class="n">X_train_var_filtered</span> <span class="o">=</span> <span class="n">variance_threshold</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="c1"># ---- Logging Feature Selection Results ----</span>
<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">(</span><span class="n">run_name</span><span class="o">=</span><span class="s2">&quot;Feature Selection Summary&quot;</span><span class="p">):</span>
    <span class="c1"># Log Correlation Threshold selection</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_param</span><span class="p">(</span><span class="s2">&quot;correlation_threshold&quot;</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;n_features_after_correlation&quot;</span><span class="p">,</span> <span class="n">X_train_corr_filtered</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    
    <span class="c1"># Log Feature Importance selection</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_param</span><span class="p">(</span><span class="s2">&quot;importance_threshold&quot;</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;n_features_after_importance&quot;</span><span class="p">,</span> <span class="n">X_train_important</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    
    <span class="c1"># Log Variance Threshold selection</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_param</span><span class="p">(</span><span class="s2">&quot;variance_threshold&quot;</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;n_features_after_variance&quot;</span><span class="p">,</span> <span class="n">X_train_var_filtered</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="c1"># ---- Model Training ----</span>

<span class="c1"># Define models</span>
<span class="n">log_reg</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;lbfgs&quot;</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s2">&quot;multinomial&quot;</span><span class="p">)</span>
<span class="n">ridge</span> <span class="o">=</span> <span class="n">RidgeClassifier</span><span class="p">()</span>
<span class="n">random_forest</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">xgb</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span><span class="n">use_label_encoder</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">eval_metric</span><span class="o">=</span><span class="s2">&quot;mlogloss&quot;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">models</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;Logistic Regression&quot;</span><span class="p">:</span> <span class="n">log_reg</span><span class="p">,</span>
    <span class="s2">&quot;Ridge Classifier&quot;</span><span class="p">:</span> <span class="n">ridge</span><span class="p">,</span>
    <span class="s2">&quot;Random Forest&quot;</span><span class="p">:</span> <span class="n">random_forest</span><span class="p">,</span>
    <span class="s2">&quot;XGBoost&quot;</span><span class="p">:</span> <span class="n">xgb</span>
<span class="p">}</span>

<span class="c1"># Function for training and evaluating models</span>
<span class="k">def</span> <span class="nf">train_and_evaluate</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">):</span>
    <span class="c1"># Create pipeline</span>
    <span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
        <span class="p">(</span><span class="s1">&#39;preprocessor&#39;</span><span class="p">,</span> <span class="n">ColumnTransformer</span><span class="p">([</span>
            <span class="p">(</span><span class="s1">&#39;num&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>  <span class="c1"># Apply scaling</span>
        <span class="p">])),</span>
        <span class="p">(</span><span class="s1">&#39;classifier&#39;</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
    <span class="p">])</span>

    <span class="c1"># Train the model</span>
    <span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="c1"># Make predictions</span>
    <span class="n">y_train_pred</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

    <span class="c1"># Evaluate the model</span>
    <span class="n">f1_train</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;weighted&quot;</span><span class="p">)</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred</span><span class="p">)</span>

    <span class="c1"># Compute confusion matrix for TP, TN, FP, FN</span>
    <span class="n">conf_matrix</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">class_name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_train</span><span class="p">)):</span>  <span class="c1"># Class labels</span>
        <span class="n">TP</span> <span class="o">=</span> <span class="n">conf_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span>
        <span class="n">TN</span> <span class="o">=</span> <span class="n">conf_matrix</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="p">(</span><span class="n">conf_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">+</span> <span class="n">conf_matrix</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="n">TP</span><span class="p">)</span>
        <span class="n">FP</span> <span class="o">=</span> <span class="n">conf_matrix</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="n">TP</span>
        <span class="n">FN</span> <span class="o">=</span> <span class="n">conf_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="n">TP</span>

        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TP_Class_</span><span class="si">{</span><span class="n">class_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">TP</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TN_Class_</span><span class="si">{</span><span class="n">class_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">TN</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;FP_Class_</span><span class="si">{</span><span class="n">class_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">FP</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;FN_Class_</span><span class="si">{</span><span class="n">class_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">FN</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2"> - Train F1 Score: </span><span class="si">{</span><span class="n">f1_train</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2"> - Accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">f1_train</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">,</span> <span class="n">conf_matrix</span>

<span class="c1"># ---- Log the results in MLFlow ----</span>

<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">(</span><span class="n">run_name</span><span class="o">=</span><span class="s2">&quot;Feature Selection and Model Evaluation&quot;</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="c1"># Log metrics for each model</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2"> Results:&quot;</span><span class="p">)</span>
        <span class="n">f1</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">,</span> <span class="n">conf_matrix</span> <span class="o">=</span> <span class="n">train_and_evaluate</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">X_train_important</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

        <span class="c1"># Log metrics</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">_train_f1&quot;</span><span class="p">,</span> <span class="n">f1</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">_train_accuracy&quot;</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>

        <span class="c1"># Log confusion matrix as an artifact</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_dict</span><span class="p">({</span><span class="s2">&quot;confusion_matrix&quot;</span><span class="p">:</span> <span class="n">conf_matrix</span><span class="o">.</span><span class="n">tolist</span><span class="p">()},</span> <span class="sa">f</span><span class="s2">&quot;confusion_matrix_</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">.json&quot;</span><span class="p">)</span>

        <span class="c1"># Log model with input example</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">sklearn</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span>
            <span class="n">sk_model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">artifact_path</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">_pipeline&quot;</span><span class="p">,</span>
            <span class="n">registered_model_name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">Pipeline&quot;</span><span class="p">,</span>
            <span class="n">input_example</span><span class="o">=</span><span class="n">X_train_important</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># Log input example to remove warnings</span>
        <span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Feature Selection and Model Evaluation Completed.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Features to drop based on correlation threshold: [&#39;feature_4&#39;]
Important features based on importance threshold: [&#39;feature_1&#39;, &#39;feature_3&#39;, &#39;feature_4&#39;]
ðŸƒ View run Feature Selection Summary at: https://dagshub.com/ryallavinuthnareddy/VINUTHNA_PYTHON_ML_PROJECT.mlflow/#/experiments/1/runs/4cd7b4b8eb2443cf8bd5a4a6cfce0980
ðŸ§ª View experiment at: https://dagshub.com/ryallavinuthnareddy/VINUTHNA_PYTHON_ML_PROJECT.mlflow/#/experiments/1
Logistic Regression Results:
Logistic Regression - Train F1 Score: 0.95
Logistic Regression - Accuracy: 0.95
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\Vanu\anaconda3\Lib\site-packages\sklearn\base.py:457: UserWarning: X has feature names, but LogisticRegression was fitted without feature names
  warnings.warn(
C:\Users\Vanu\anaconda3\Lib\site-packages\mlflow\types\utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values &lt;https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values&gt;`_ for more details.
  warnings.warn(
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "e0d53d43739f47e0bd78248f0c74ee1a", "version_major": 2, "version_minor": 0}</script><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\Vanu\anaconda3\Lib\site-packages\sklearn\base.py:457: UserWarning: X has feature names, but LogisticRegression was fitted without feature names
  warnings.warn(
Registered model &#39;Logistic RegressionPipeline&#39; already exists. Creating a new version of this model...
2024/12/19 20:11:09 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Logistic RegressionPipeline, version 3
Created version &#39;3&#39; of model &#39;Logistic RegressionPipeline&#39;.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Ridge Classifier Results:
Ridge Classifier - Train F1 Score: 0.812912389741658
Ridge Classifier - Accuracy: 0.8166666666666667
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\Vanu\anaconda3\Lib\site-packages\sklearn\base.py:457: UserWarning: X has feature names, but RidgeClassifier was fitted without feature names
  warnings.warn(
C:\Users\Vanu\anaconda3\Lib\site-packages\mlflow\types\utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values &lt;https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values&gt;`_ for more details.
  warnings.warn(
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "27fc28c1ca3449f699c8861c1c40f916", "version_major": 2, "version_minor": 0}</script><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\Vanu\anaconda3\Lib\site-packages\sklearn\base.py:457: UserWarning: X has feature names, but RidgeClassifier was fitted without feature names
  warnings.warn(
Registered model &#39;Ridge ClassifierPipeline&#39; already exists. Creating a new version of this model...
2024/12/19 20:11:35 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Ridge ClassifierPipeline, version 3
Created version &#39;3&#39; of model &#39;Ridge ClassifierPipeline&#39;.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Random Forest Results:
Random Forest - Train F1 Score: 1.0
Random Forest - Accuracy: 1.0
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\Vanu\anaconda3\Lib\site-packages\sklearn\base.py:457: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names
  warnings.warn(
C:\Users\Vanu\anaconda3\Lib\site-packages\mlflow\types\utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values &lt;https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values&gt;`_ for more details.
  warnings.warn(
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "ecffd5cba0d244579198be3be8ae4fe5", "version_major": 2, "version_minor": 0}</script><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\Vanu\anaconda3\Lib\site-packages\sklearn\base.py:457: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names
  warnings.warn(
Registered model &#39;Random ForestPipeline&#39; already exists. Creating a new version of this model...
2024/12/19 20:12:01 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Random ForestPipeline, version 3
Created version &#39;3&#39; of model &#39;Random ForestPipeline&#39;.
C:\Users\Vanu\anaconda3\Lib\site-packages\xgboost\core.py:158: UserWarning: [20:12:01] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { &quot;use_label_encoder&quot; } are not used.

  warnings.warn(smsg, UserWarning)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>XGBoost Results:
XGBoost - Train F1 Score: 1.0
XGBoost - Accuracy: 1.0
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\Vanu\anaconda3\Lib\site-packages\mlflow\types\utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values &lt;https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values&gt;`_ for more details.
  warnings.warn(
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "9c6f626fb1824769a4fc6b77055108d7", "version_major": 2, "version_minor": 0}</script><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Registered model &#39;XGBoostPipeline&#39; already exists. Creating a new version of this model...
2024/12/19 20:12:27 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: XGBoostPipeline, version 4
Created version &#39;4&#39; of model &#39;XGBoostPipeline&#39;.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>ðŸƒ View run Feature Selection and Model Evaluation at: https://dagshub.com/ryallavinuthnareddy/VINUTHNA_PYTHON_ML_PROJECT.mlflow/#/experiments/1/runs/cfae45a3e2f7482e9b5539e5044b736a
ðŸ§ª View experiment at: https://dagshub.com/ryallavinuthnareddy/VINUTHNA_PYTHON_ML_PROJECT.mlflow/#/experiments/1
Feature Selection and Model Evaluation Completed.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mlflow</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Connect to MLFlow</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_tracking_uri</span><span class="p">(</span><span class="s2">&quot;https://dagshub.com/ryallavinuthnareddy/VINUTHNA_PYTHON_ML_PROJECT.mlflow&quot;</span><span class="p">)</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_experiment</span><span class="p">(</span><span class="s2">&quot;VINUTHNA_PYTHON_ML_PROJECT_EXPERIMENT&quot;</span><span class="p">)</span>

<span class="c1"># Load dataset</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">feature_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;feature_1&quot;</span><span class="p">,</span> <span class="s2">&quot;feature_2&quot;</span><span class="p">,</span> <span class="s2">&quot;feature_3&quot;</span><span class="p">,</span> <span class="s2">&quot;feature_4&quot;</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">feature_names</span><span class="p">)</span>

<span class="c1"># Train-test split</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># ---- Apply PCA for Dimensionality Reduction ----</span>

<span class="c1"># Standard Scaling for PCA</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Apply PCA</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">()</span>
<span class="n">X_train_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">)</span>

<span class="c1"># Explained Variance Ratio (Scree Plot)</span>
<span class="n">explained_variance_ratio</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span>
<span class="n">cumulative_explained_variance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">explained_variance_ratio</span><span class="p">)</span>

<span class="c1"># Scree plot to visualize which components to select</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">explained_variance_ratio</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">cumulative_explained_variance</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of Principal Components&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Cumulative Explained Variance&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Scree Plot&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Save the plot as a PNG file</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;scree_plot.png&#39;</span><span class="p">)</span>

<span class="c1"># Log the scree plot and PCA results</span>
<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">(</span><span class="n">run_name</span><span class="o">=</span><span class="s2">&quot;PCA for Dimensionality Reduction&quot;</span><span class="p">):</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_param</span><span class="p">(</span><span class="s2">&quot;n_components&quot;</span><span class="p">,</span> <span class="n">X_train_pca</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;total_explained_variance&quot;</span><span class="p">,</span> <span class="n">cumulative_explained_variance</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_artifact</span><span class="p">(</span><span class="s1">&#39;scree_plot.png&#39;</span><span class="p">)</span>  <span class="c1"># Log the saved scree plot image</span>

<span class="c1"># ---- Select Number of Components Based on Scree Plot ----</span>
<span class="c1"># Let&#39;s select components that explain at least 95% of the variance</span>
<span class="n">threshold</span> <span class="o">=</span> <span class="mf">0.95</span>
<span class="n">num_components</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">cumulative_explained_variance</span> <span class="o">&gt;=</span> <span class="n">threshold</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of components selected to explain </span><span class="si">{</span><span class="n">threshold</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="si">}</span><span class="s2">% variance: </span><span class="si">{</span><span class="n">num_components</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Apply PCA again with selected components</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="n">num_components</span><span class="p">)</span>
<span class="n">X_train_pca_selected</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">)</span>
<span class="n">X_test_pca_selected</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>

<span class="c1"># ---- Model Training and Evaluation ----</span>

<span class="c1"># Define models</span>
<span class="n">log_reg</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;lbfgs&quot;</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s2">&quot;multinomial&quot;</span><span class="p">)</span>
<span class="n">ridge</span> <span class="o">=</span> <span class="n">RidgeClassifier</span><span class="p">()</span>
<span class="n">random_forest</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">xgb</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span><span class="n">use_label_encoder</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">eval_metric</span><span class="o">=</span><span class="s2">&quot;mlogloss&quot;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">models</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;Logistic Regression&quot;</span><span class="p">:</span> <span class="n">log_reg</span><span class="p">,</span>
    <span class="s2">&quot;Ridge Classifier&quot;</span><span class="p">:</span> <span class="n">ridge</span><span class="p">,</span>
    <span class="s2">&quot;Random Forest&quot;</span><span class="p">:</span> <span class="n">random_forest</span><span class="p">,</span>
    <span class="s2">&quot;XGBoost&quot;</span><span class="p">:</span> <span class="n">xgb</span>
<span class="p">}</span>

<span class="c1"># Function for training and evaluating models</span>
<span class="k">def</span> <span class="nf">train_and_evaluate</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">):</span>
    <span class="c1"># Create pipeline</span>
    <span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
        <span class="p">(</span><span class="s1">&#39;classifier&#39;</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
    <span class="p">])</span>

    <span class="c1"># Train the model</span>
    <span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="c1"># Make predictions</span>
    <span class="n">y_train_pred</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

    <span class="c1"># Evaluate the model</span>
    <span class="n">f1_train</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;weighted&quot;</span><span class="p">)</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred</span><span class="p">)</span>

    <span class="c1"># Compute confusion matrix for TP, TN, FP, FN</span>
    <span class="n">conf_matrix</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">class_name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_train</span><span class="p">)):</span>  <span class="c1"># Class labels</span>
        <span class="n">TP</span> <span class="o">=</span> <span class="n">conf_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span>
        <span class="n">TN</span> <span class="o">=</span> <span class="n">conf_matrix</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="p">(</span><span class="n">conf_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">+</span> <span class="n">conf_matrix</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="n">TP</span><span class="p">)</span>
        <span class="n">FP</span> <span class="o">=</span> <span class="n">conf_matrix</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="n">TP</span>
        <span class="n">FN</span> <span class="o">=</span> <span class="n">conf_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="n">TP</span>

        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TP_Class_</span><span class="si">{</span><span class="n">class_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">TP</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TN_Class_</span><span class="si">{</span><span class="n">class_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">TN</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;FP_Class_</span><span class="si">{</span><span class="n">class_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">FP</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;FN_Class_</span><span class="si">{</span><span class="n">class_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">FN</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2"> - Train F1 Score: </span><span class="si">{</span><span class="n">f1_train</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2"> - Accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">f1_train</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">,</span> <span class="n">conf_matrix</span>

<span class="c1"># ---- Log the results in MLFlow ----</span>

<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">(</span><span class="n">run_name</span><span class="o">=</span><span class="s2">&quot;PCA with Feature Selection and Model Evaluation&quot;</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="c1"># Log metrics for each model</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2"> Results:&quot;</span><span class="p">)</span>
        <span class="n">f1</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">,</span> <span class="n">conf_matrix</span> <span class="o">=</span> <span class="n">train_and_evaluate</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">X_train_pca_selected</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

        <span class="c1"># Log metrics</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">_train_f1&quot;</span><span class="p">,</span> <span class="n">f1</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">_train_accuracy&quot;</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>

        <span class="c1"># Log confusion matrix as an artifact</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_dict</span><span class="p">({</span><span class="s2">&quot;confusion_matrix&quot;</span><span class="p">:</span> <span class="n">conf_matrix</span><span class="o">.</span><span class="n">tolist</span><span class="p">()},</span> <span class="sa">f</span><span class="s2">&quot;confusion_matrix_</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">.json&quot;</span><span class="p">)</span>

        <span class="c1"># Log model with input example</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">sklearn</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span>
            <span class="n">sk_model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">artifact_path</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">_pipeline&quot;</span><span class="p">,</span>
            <span class="n">registered_model_name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">Pipeline&quot;</span><span class="p">,</span>
            <span class="n">input_example</span><span class="o">=</span><span class="n">X_train_pca_selected</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># Log input example to remove warnings</span>
        <span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;PCA and Model Evaluation Completed.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>ðŸƒ View run PCA for Dimensionality Reduction at: https://dagshub.com/ryallavinuthnareddy/VINUTHNA_PYTHON_ML_PROJECT.mlflow/#/experiments/1/runs/b2b7605c1f2e49e3adaf2ca13092dd46
ðŸ§ª View experiment at: https://dagshub.com/ryallavinuthnareddy/VINUTHNA_PYTHON_ML_PROJECT.mlflow/#/experiments/1
Number of components selected to explain 95.0% variance: 2
Logistic Regression Results:
Logistic Regression - Train F1 Score: 0.9166666666666666
Logistic Regression - Accuracy: 0.9166666666666666
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "67b0995e1ccb4dcaa11e41f98f70026c", "version_major": 2, "version_minor": 0}</script><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Registered model &#39;Logistic RegressionPipeline&#39; already exists. Creating a new version of this model...
2024/12/19 20:30:55 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Logistic RegressionPipeline, version 4
Created version &#39;4&#39; of model &#39;Logistic RegressionPipeline&#39;.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Ridge Classifier Results:
Ridge Classifier - Train F1 Score: 0.791194027409806
Ridge Classifier - Accuracy: 0.7916666666666666
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "8fb4789d46b2408592fe2cf8fc3b0b30", "version_major": 2, "version_minor": 0}</script><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Registered model &#39;Ridge ClassifierPipeline&#39; already exists. Creating a new version of this model...
2024/12/19 20:31:21 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Ridge ClassifierPipeline, version 4
Created version &#39;4&#39; of model &#39;Ridge ClassifierPipeline&#39;.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Random Forest Results:
Random Forest - Train F1 Score: 1.0
Random Forest - Accuracy: 1.0
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "4b82f1952f09420b87dc8aba599c9fa0", "version_major": 2, "version_minor": 0}</script><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Registered model &#39;Random ForestPipeline&#39; already exists. Creating a new version of this model...
2024/12/19 20:31:47 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Random ForestPipeline, version 4
Created version &#39;4&#39; of model &#39;Random ForestPipeline&#39;.
C:\Users\Vanu\anaconda3\Lib\site-packages\xgboost\core.py:158: UserWarning: [20:31:47] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { &quot;use_label_encoder&quot; } are not used.

  warnings.warn(smsg, UserWarning)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>XGBoost Results:
XGBoost - Train F1 Score: 1.0
XGBoost - Accuracy: 1.0
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "fafbd476b1ff48ec82fe3debe2def795", "version_major": 2, "version_minor": 0}</script><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Registered model &#39;XGBoostPipeline&#39; already exists. Creating a new version of this model...
2024/12/19 20:32:13 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: XGBoostPipeline, version 5
Created version &#39;5&#39; of model &#39;XGBoostPipeline&#39;.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>ðŸƒ View run PCA with Feature Selection and Model Evaluation at: https://dagshub.com/ryallavinuthnareddy/VINUTHNA_PYTHON_ML_PROJECT.mlflow/#/experiments/1/runs/6f3949a7af02407983eb2b7c95df79dd
ðŸ§ª View experiment at: https://dagshub.com/ryallavinuthnareddy/VINUTHNA_PYTHON_ML_PROJECT.mlflow/#/experiments/1
PCA and Model Evaluation Completed.
</pre></div>
</div>
<img alt="_images/2f6459f40e71f1c1f8ee1237aa90301e54a80a0b401eba0ff1dcb4bd3ed55533.png" src="_images/2f6459f40e71f1c1f8ee1237aa90301e54a80a0b401eba0ff1dcb4bd3ed55533.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mlflow</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">mutual_info_classif</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">XGBClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">ColumnTransformer</span>

<span class="c1"># Connect to MLFlow</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_tracking_uri</span><span class="p">(</span><span class="s2">&quot;https://dagshub.com/ryallavinuthnareddy/VINUTHNA_PYTHON_ML_PROJECT.mlflow&quot;</span><span class="p">)</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_experiment</span><span class="p">(</span><span class="s2">&quot;VINUTHNA_PYTHON_ML_PROJECT_EXPERIMENT&quot;</span><span class="p">)</span>

<span class="c1"># Load dataset</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">feature_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;feature_1&quot;</span><span class="p">,</span> <span class="s2">&quot;feature_2&quot;</span><span class="p">,</span> <span class="s2">&quot;feature_3&quot;</span><span class="p">,</span> <span class="s2">&quot;feature_4&quot;</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">feature_names</span><span class="p">)</span>

<span class="c1"># Train-test split</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Feature Selection Using Mutual Information</span>
<span class="k">def</span> <span class="nf">feature_selection_mutual_info</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
    <span class="c1"># Calculate mutual information between features and target</span>
    <span class="n">mi</span> <span class="o">=</span> <span class="n">mutual_info_classif</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    
    <span class="c1"># Select features with mutual information above the threshold</span>
    <span class="n">selected_features</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">mi</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Selected features based on mutual information: </span><span class="si">{</span><span class="n">selected_features</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">X_train</span><span class="p">[</span><span class="n">selected_features</span><span class="p">]</span>

<span class="c1"># Apply feature selection</span>
<span class="n">X_train_selected</span> <span class="o">=</span> <span class="n">feature_selection_mutual_info</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># ---- Model Training ----</span>
<span class="n">log_reg</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;lbfgs&quot;</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s2">&quot;multinomial&quot;</span><span class="p">)</span>
<span class="n">random_forest</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">xgb</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span><span class="n">use_label_encoder</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">eval_metric</span><span class="o">=</span><span class="s2">&quot;mlogloss&quot;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">models</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;Logistic Regression&quot;</span><span class="p">:</span> <span class="n">log_reg</span><span class="p">,</span>
    <span class="s2">&quot;Random Forest&quot;</span><span class="p">:</span> <span class="n">random_forest</span><span class="p">,</span>
    <span class="s2">&quot;XGBoost&quot;</span><span class="p">:</span> <span class="n">xgb</span>
<span class="p">}</span>

<span class="c1"># Function for training and evaluating models</span>
<span class="k">def</span> <span class="nf">train_and_evaluate</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">):</span>
    <span class="c1"># Create pipeline</span>
    <span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
        <span class="p">(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>  <span class="c1"># Apply scaling</span>
        <span class="p">(</span><span class="s1">&#39;classifier&#39;</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
    <span class="p">])</span>

    <span class="c1"># Train the model</span>
    <span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="c1"># Make predictions</span>
    <span class="n">y_train_pred</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

    <span class="c1"># Evaluate the model</span>
    <span class="n">f1_train</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;weighted&quot;</span><span class="p">)</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred</span><span class="p">)</span>

    <span class="c1"># Compute confusion matrix for TP, TN, FP, FN</span>
    <span class="n">conf_matrix</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">class_name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_train</span><span class="p">)):</span>  <span class="c1"># Class labels</span>
        <span class="n">TP</span> <span class="o">=</span> <span class="n">conf_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span>
        <span class="n">TN</span> <span class="o">=</span> <span class="n">conf_matrix</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="p">(</span><span class="n">conf_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">+</span> <span class="n">conf_matrix</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="n">TP</span><span class="p">)</span>
        <span class="n">FP</span> <span class="o">=</span> <span class="n">conf_matrix</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="n">TP</span>
        <span class="n">FN</span> <span class="o">=</span> <span class="n">conf_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="n">TP</span>

        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TP_Class_</span><span class="si">{</span><span class="n">class_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">TP</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TN_Class_</span><span class="si">{</span><span class="n">class_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">TN</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;FP_Class_</span><span class="si">{</span><span class="n">class_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">FP</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;FN_Class_</span><span class="si">{</span><span class="n">class_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">FN</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2"> - Train F1 Score: </span><span class="si">{</span><span class="n">f1_train</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2"> - Accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">f1_train</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">,</span> <span class="n">conf_matrix</span>

<span class="c1"># Log the results in MLFlow</span>
<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">(</span><span class="n">run_name</span><span class="o">=</span><span class="s2">&quot;Custom Feature Selection Experiment&quot;</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2"> Results:&quot;</span><span class="p">)</span>
        <span class="n">f1</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">,</span> <span class="n">conf_matrix</span> <span class="o">=</span> <span class="n">train_and_evaluate</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">X_train_selected</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

        <span class="c1"># Log metrics</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">_train_f1&quot;</span><span class="p">,</span> <span class="n">f1</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">_train_accuracy&quot;</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>

        <span class="c1"># Log confusion matrix as an artifact</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_dict</span><span class="p">({</span><span class="s2">&quot;confusion_matrix&quot;</span><span class="p">:</span> <span class="n">conf_matrix</span><span class="o">.</span><span class="n">tolist</span><span class="p">()},</span> <span class="sa">f</span><span class="s2">&quot;confusion_matrix_</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">.json&quot;</span><span class="p">)</span>

        <span class="c1"># Log model with input example</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">sklearn</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span>
            <span class="n">sk_model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">artifact_path</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">_pipeline&quot;</span><span class="p">,</span>
            <span class="n">registered_model_name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">Pipeline&quot;</span><span class="p">,</span>
            <span class="n">input_example</span><span class="o">=</span><span class="n">X_train_selected</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># Log input example to remove warnings</span>
        <span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Custom Feature Selection and Model Evaluation Completed.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Selected features based on mutual information: Index([&#39;feature_1&#39;, &#39;feature_2&#39;, &#39;feature_3&#39;, &#39;feature_4&#39;], dtype=&#39;object&#39;)
Logistic Regression Results:
Logistic Regression - Train F1 Score: 0.9666666666666667
Logistic Regression - Accuracy: 0.9666666666666667
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\Vanu\anaconda3\Lib\site-packages\sklearn\base.py:457: UserWarning: X has feature names, but LogisticRegression was fitted without feature names
  warnings.warn(
C:\Users\Vanu\anaconda3\Lib\site-packages\mlflow\types\utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values &lt;https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values&gt;`_ for more details.
  warnings.warn(
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "798be27a98134eb8836fa000f096cdc2", "version_major": 2, "version_minor": 0}</script><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\Vanu\anaconda3\Lib\site-packages\sklearn\base.py:457: UserWarning: X has feature names, but LogisticRegression was fitted without feature names
  warnings.warn(
Registered model &#39;Logistic RegressionPipeline&#39; already exists. Creating a new version of this model...
2024/12/19 20:35:47 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Logistic RegressionPipeline, version 5
Created version &#39;5&#39; of model &#39;Logistic RegressionPipeline&#39;.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Random Forest Results:
Random Forest - Train F1 Score: 1.0
Random Forest - Accuracy: 1.0
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\Vanu\anaconda3\Lib\site-packages\sklearn\base.py:457: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names
  warnings.warn(
C:\Users\Vanu\anaconda3\Lib\site-packages\mlflow\types\utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values &lt;https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values&gt;`_ for more details.
  warnings.warn(
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "c820471dab1442a8ba38a50277e90e72", "version_major": 2, "version_minor": 0}</script><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\Vanu\anaconda3\Lib\site-packages\sklearn\base.py:457: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names
  warnings.warn(
Registered model &#39;Random ForestPipeline&#39; already exists. Creating a new version of this model...
2024/12/19 20:36:13 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Random ForestPipeline, version 5
Created version &#39;5&#39; of model &#39;Random ForestPipeline&#39;.
C:\Users\Vanu\anaconda3\Lib\site-packages\xgboost\core.py:158: UserWarning: [20:36:13] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { &quot;use_label_encoder&quot; } are not used.

  warnings.warn(smsg, UserWarning)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>XGBoost Results:
XGBoost - Train F1 Score: 1.0
XGBoost - Accuracy: 1.0
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\Vanu\anaconda3\Lib\site-packages\mlflow\types\utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values &lt;https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values&gt;`_ for more details.
  warnings.warn(
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "2d58ea1ec1424bbd877ba019d1401dff", "version_major": 2, "version_minor": 0}</script><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Registered model &#39;XGBoostPipeline&#39; already exists. Creating a new version of this model...
2024/12/19 20:36:39 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: XGBoostPipeline, version 6
Created version &#39;6&#39; of model &#39;XGBoostPipeline&#39;.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>ðŸƒ View run Custom Feature Selection Experiment at: https://dagshub.com/ryallavinuthnareddy/VINUTHNA_PYTHON_ML_PROJECT.mlflow/#/experiments/1/runs/8e2a4d6311db4502a4584732b644cb00
ðŸ§ª View experiment at: https://dagshub.com/ryallavinuthnareddy/VINUTHNA_PYTHON_ML_PROJECT.mlflow/#/experiments/1
Custom Feature Selection and Model Evaluation Completed.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Experiment #7: Feature Engineering Experiment</span>
<span class="kn">import</span> <span class="nn">mlflow</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">FunctionTransformer</span><span class="p">,</span> <span class="n">PolynomialFeatures</span><span class="p">,</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">XGBClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">ColumnTransformer</span>

<span class="c1"># Connect to MLFlow</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_tracking_uri</span><span class="p">(</span><span class="s2">&quot;https://dagshub.com/ryallavinuthnareddy/VINUTHNA_PYTHON_ML_PROJECT.mlflow&quot;</span><span class="p">)</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_experiment</span><span class="p">(</span><span class="s2">&quot;VINUTHNA_PYTHON_ML_PROJECT_EXPERIMENT&quot;</span><span class="p">)</span>

<span class="c1"># Load dataset</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">feature_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;feature_1&quot;</span><span class="p">,</span> <span class="s2">&quot;feature_2&quot;</span><span class="p">,</span> <span class="s2">&quot;feature_3&quot;</span><span class="p">,</span> <span class="s2">&quot;feature_4&quot;</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">feature_names</span><span class="p">)</span>

<span class="c1"># Train-test split</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># ---- Feature Engineering ----</span>
<span class="c1"># 1. Log Transformation</span>
<span class="n">log_transformer</span> <span class="o">=</span> <span class="n">FunctionTransformer</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log1p</span><span class="p">,</span> <span class="n">validate</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">X_train_log</span> <span class="o">=</span> <span class="n">log_transformer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_log</span> <span class="o">=</span> <span class="n">log_transformer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># 2. Polynomial Features</span>
<span class="n">poly</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">include_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">X_train_poly</span> <span class="o">=</span> <span class="n">poly</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_poly</span> <span class="o">=</span> <span class="n">poly</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># 3. Feature Combination</span>
<span class="n">X_train</span><span class="p">[</span><span class="s1">&#39;feature_combination&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="s1">&#39;feature_1&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">X_train</span><span class="p">[</span><span class="s1">&#39;feature_2&#39;</span><span class="p">]</span>
<span class="n">X_test</span><span class="p">[</span><span class="s1">&#39;feature_combination&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">[</span><span class="s1">&#39;feature_1&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">X_test</span><span class="p">[</span><span class="s1">&#39;feature_2&#39;</span><span class="p">]</span>

<span class="c1"># ---- Model Training ----</span>
<span class="n">log_reg</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;lbfgs&quot;</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s2">&quot;multinomial&quot;</span><span class="p">)</span>
<span class="n">ridge</span> <span class="o">=</span> <span class="n">RidgeClassifier</span><span class="p">()</span>
<span class="n">random_forest</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">xgb</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span><span class="n">use_label_encoder</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">eval_metric</span><span class="o">=</span><span class="s2">&quot;mlogloss&quot;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">models</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;Logistic Regression&quot;</span><span class="p">:</span> <span class="n">log_reg</span><span class="p">,</span>
    <span class="s2">&quot;Ridge Classifier&quot;</span><span class="p">:</span> <span class="n">ridge</span><span class="p">,</span>
    <span class="s2">&quot;Random Forest&quot;</span><span class="p">:</span> <span class="n">random_forest</span><span class="p">,</span>
    <span class="s2">&quot;XGBoost&quot;</span><span class="p">:</span> <span class="n">xgb</span>
<span class="p">}</span>

<span class="c1"># Function for training and evaluating models</span>
<span class="k">def</span> <span class="nf">train_and_evaluate</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">):</span>
    <span class="c1"># Create pipeline</span>
    <span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
        <span class="p">(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>  <span class="c1"># Apply scaling</span>
        <span class="p">(</span><span class="s1">&#39;classifier&#39;</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
    <span class="p">])</span>

    <span class="c1"># Train the model</span>
    <span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="c1"># Make predictions</span>
    <span class="n">y_train_pred</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

    <span class="c1"># Evaluate the model</span>
    <span class="n">f1_train</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;weighted&quot;</span><span class="p">)</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred</span><span class="p">)</span>

    <span class="c1"># Compute confusion matrix for TP, TN, FP, FN</span>
    <span class="n">conf_matrix</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">class_name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_train</span><span class="p">)):</span>  <span class="c1"># Class labels</span>
        <span class="n">TP</span> <span class="o">=</span> <span class="n">conf_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span>
        <span class="n">TN</span> <span class="o">=</span> <span class="n">conf_matrix</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="p">(</span><span class="n">conf_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">+</span> <span class="n">conf_matrix</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="n">TP</span><span class="p">)</span>
        <span class="n">FP</span> <span class="o">=</span> <span class="n">conf_matrix</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="n">TP</span>
        <span class="n">FN</span> <span class="o">=</span> <span class="n">conf_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="n">TP</span>

        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TP_Class_</span><span class="si">{</span><span class="n">class_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">TP</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TN_Class_</span><span class="si">{</span><span class="n">class_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">TN</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;FP_Class_</span><span class="si">{</span><span class="n">class_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">FP</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;FN_Class_</span><span class="si">{</span><span class="n">class_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">FN</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2"> - Train F1 Score: </span><span class="si">{</span><span class="n">f1_train</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2"> - Accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">f1_train</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">,</span> <span class="n">conf_matrix</span>

<span class="c1"># Log the results in MLFlow</span>
<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">(</span><span class="n">run_name</span><span class="o">=</span><span class="s2">&quot;Feature Engineering Experiment&quot;</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2"> Results:&quot;</span><span class="p">)</span>
        <span class="n">f1</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">,</span> <span class="n">conf_matrix</span> <span class="o">=</span> <span class="n">train_and_evaluate</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

        <span class="c1"># Log metrics</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">_train_f1&quot;</span><span class="p">,</span> <span class="n">f1</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">_train_accuracy&quot;</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>

        <span class="c1"># Log confusion matrix as an artifact</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_dict</span><span class="p">({</span><span class="s2">&quot;confusion_matrix&quot;</span><span class="p">:</span> <span class="n">conf_matrix</span><span class="o">.</span><span class="n">tolist</span><span class="p">()},</span> <span class="sa">f</span><span class="s2">&quot;confusion_matrix_</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">.json&quot;</span><span class="p">)</span>

        <span class="c1"># Log model with input example</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">sklearn</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span>
            <span class="n">sk_model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">artifact_path</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">_pipeline&quot;</span><span class="p">,</span>
            <span class="n">registered_model_name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">Pipeline&quot;</span><span class="p">,</span>
            <span class="n">input_example</span><span class="o">=</span><span class="n">X_train</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># Log input example to remove warnings</span>
        <span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Feature Engineering and Model Evaluation Completed.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Logistic Regression Results:
Logistic Regression - Train F1 Score: 0.9666666666666667
Logistic Regression - Accuracy: 0.9666666666666667
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\Vanu\anaconda3\Lib\site-packages\sklearn\base.py:457: UserWarning: X has feature names, but LogisticRegression was fitted without feature names
  warnings.warn(
C:\Users\Vanu\anaconda3\Lib\site-packages\mlflow\types\utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values &lt;https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values&gt;`_ for more details.
  warnings.warn(
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "d7ae5308b7b74cd8844cbc323c9997d6", "version_major": 2, "version_minor": 0}</script><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\Vanu\anaconda3\Lib\site-packages\sklearn\base.py:457: UserWarning: X has feature names, but LogisticRegression was fitted without feature names
  warnings.warn(
Registered model &#39;Logistic RegressionPipeline&#39; already exists. Creating a new version of this model...
2024/12/19 20:37:21 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Logistic RegressionPipeline, version 6
Created version &#39;6&#39; of model &#39;Logistic RegressionPipeline&#39;.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Ridge Classifier Results:
Ridge Classifier - Train F1 Score: 0.8491667354827546
Ridge Classifier - Accuracy: 0.85
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\Vanu\anaconda3\Lib\site-packages\sklearn\base.py:457: UserWarning: X has feature names, but RidgeClassifier was fitted without feature names
  warnings.warn(
C:\Users\Vanu\anaconda3\Lib\site-packages\mlflow\types\utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values &lt;https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values&gt;`_ for more details.
  warnings.warn(
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "98d18e7ddb094e53a00cae4003cdfd18", "version_major": 2, "version_minor": 0}</script><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\Vanu\anaconda3\Lib\site-packages\sklearn\base.py:457: UserWarning: X has feature names, but RidgeClassifier was fitted without feature names
  warnings.warn(
Registered model &#39;Ridge ClassifierPipeline&#39; already exists. Creating a new version of this model...
2024/12/19 20:37:47 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Ridge ClassifierPipeline, version 5
Created version &#39;5&#39; of model &#39;Ridge ClassifierPipeline&#39;.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Random Forest Results:
Random Forest - Train F1 Score: 1.0
Random Forest - Accuracy: 1.0
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\Vanu\anaconda3\Lib\site-packages\sklearn\base.py:457: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names
  warnings.warn(
C:\Users\Vanu\anaconda3\Lib\site-packages\mlflow\types\utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values &lt;https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values&gt;`_ for more details.
  warnings.warn(
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "0688cb4511da491ba73df9a76bdfd460", "version_major": 2, "version_minor": 0}</script><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\Vanu\anaconda3\Lib\site-packages\sklearn\base.py:457: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names
  warnings.warn(
Registered model &#39;Random ForestPipeline&#39; already exists. Creating a new version of this model...
2024/12/19 20:38:13 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Random ForestPipeline, version 6
Created version &#39;6&#39; of model &#39;Random ForestPipeline&#39;.
C:\Users\Vanu\anaconda3\Lib\site-packages\xgboost\core.py:158: UserWarning: [20:38:13] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { &quot;use_label_encoder&quot; } are not used.

  warnings.warn(smsg, UserWarning)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>XGBoost Results:
XGBoost - Train F1 Score: 1.0
XGBoost - Accuracy: 1.0
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\Vanu\anaconda3\Lib\site-packages\mlflow\types\utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values &lt;https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values&gt;`_ for more details.
  warnings.warn(
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "4f45d53b2a7849bcb884c6e45a412060", "version_major": 2, "version_minor": 0}</script><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Registered model &#39;XGBoostPipeline&#39; already exists. Creating a new version of this model...
2024/12/19 20:38:39 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: XGBoostPipeline, version 7
Created version &#39;7&#39; of model &#39;XGBoostPipeline&#39;.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>ðŸƒ View run Feature Engineering Experiment at: https://dagshub.com/ryallavinuthnareddy/VINUTHNA_PYTHON_ML_PROJECT.mlflow/#/experiments/1/runs/a67cdf7281c44c90a9b6f8f4974199b7
ðŸ§ª View experiment at: https://dagshub.com/ryallavinuthnareddy/VINUTHNA_PYTHON_ML_PROJECT.mlflow/#/experiments/1
Feature Engineering and Model Evaluation Completed.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># F1-scores from Experiment 2 to Experiment 7 for each model</span>
<span class="c1"># Example data for each model from Experiments 2 to 7</span>
<span class="n">f1_scores</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;Logistic Regression&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.9666666667</span><span class="p">,</span> <span class="mf">0.8831874088</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">,</span> <span class="mf">0.9666666667</span><span class="p">,</span> <span class="mf">0.9166666667</span><span class="p">,</span> <span class="mf">0.9666666667</span><span class="p">],</span>
    <span class="s2">&quot;Ridge Classifier&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.813174603</span><span class="p">,</span> <span class="mf">0.8222582687</span><span class="p">,</span> <span class="mf">0.8129123897</span><span class="p">,</span> <span class="mf">0.8166666667</span><span class="p">,</span> <span class="mf">0.8491667355</span><span class="p">,</span> <span class="mf">0.85</span><span class="p">],</span>
    <span class="s2">&quot;Random Forest&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="s2">&quot;XGBoost&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="p">}</span>

<span class="c1"># Labels for experiments</span>
<span class="n">experiments</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Exp 2&quot;</span><span class="p">,</span> <span class="s2">&quot;Exp 3&quot;</span><span class="p">,</span> <span class="s2">&quot;Exp 4&quot;</span><span class="p">,</span> <span class="s2">&quot;Exp 5&quot;</span><span class="p">,</span> <span class="s2">&quot;Exp 6&quot;</span><span class="p">,</span> <span class="s2">&quot;Exp 7&quot;</span><span class="p">]</span>

<span class="c1"># Set the position for each bar group (model)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">experiments</span><span class="p">))</span>  <span class="c1"># X-axis labels for experiments</span>
<span class="n">width</span> <span class="o">=</span> <span class="mf">0.2</span>  <span class="c1"># Bar width</span>

<span class="c1"># Create the plot</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>

<span class="c1"># Plot the bars for each model</span>
<span class="n">rects1</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">width</span><span class="o">*</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">f1_scores</span><span class="p">[</span><span class="s2">&quot;Logistic Regression&quot;</span><span class="p">],</span> <span class="n">width</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Logistic Regression&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">)</span>
<span class="n">rects2</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">width</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">f1_scores</span><span class="p">[</span><span class="s2">&quot;Ridge Classifier&quot;</span><span class="p">],</span> <span class="n">width</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Ridge Classifier&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">)</span>
<span class="n">rects3</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">width</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">f1_scores</span><span class="p">[</span><span class="s2">&quot;Random Forest&quot;</span><span class="p">],</span> <span class="n">width</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Random Forest&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">)</span>
<span class="n">rects4</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">width</span><span class="o">*</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">f1_scores</span><span class="p">[</span><span class="s2">&quot;XGBoost&quot;</span><span class="p">],</span> <span class="n">width</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;XGBoost&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">)</span>

<span class="c1"># Add labels, title, and custom x-axis tick labels</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Experiments&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;F1-score&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;F1-score Comparison Across Experiments for Different Models&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">experiments</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="c1"># Show the plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># Set the Y-axis limit from 0 to 1 (for F1-score)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/aa42446c05bb110c179538b042ab5ae40e4108f618369e3e2b22c67ebbee037a.png" src="_images/aa42446c05bb110c179538b042ab5ae40e4108f618369e3e2b22c67ebbee037a.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">joblib</span>

<span class="c1"># Save the trained Logistic Regression model</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">best_model</span><span class="p">,</span> <span class="s1">&#39;logistic_regression_model.joblib&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;logistic_regression_model.joblib&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>fastapi<span class="w"> </span>uvicorn
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Collecting fastapi
  Obtaining dependency information for fastapi from https://files.pythonhosted.org/packages/52/b3/7e4df40e585df024fac2f80d1a2d579c854ac37109675db2b0cc22c0bb9e/fastapi-0.115.6-py3-none-any.whl.metadata
  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)
Collecting uvicorn
  Obtaining dependency information for uvicorn from https://files.pythonhosted.org/packages/61/14/33a3a1352cfa71812a3a21e8c9bfb83f60b0011f5e36f2b1399d51928209/uvicorn-0.34.0-py3-none-any.whl.metadata
  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)
Collecting starlette&lt;0.42.0,&gt;=0.40.0 (from fastapi)
  Obtaining dependency information for starlette&lt;0.42.0,&gt;=0.40.0 from https://files.pythonhosted.org/packages/96/00/2b325970b3060c7cecebab6d295afe763365822b1306a12eeab198f74323/starlette-0.41.3-py3-none-any.whl.metadata
  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)
Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,&lt;3.0.0,&gt;=1.7.4 in c:\users\vanu\anaconda3\lib\site-packages (from fastapi) (2.10.4)
Requirement already satisfied: typing-extensions&gt;=4.8.0 in c:\users\vanu\anaconda3\lib\site-packages (from fastapi) (4.12.2)
Requirement already satisfied: click&gt;=7.0 in c:\users\vanu\anaconda3\lib\site-packages (from uvicorn) (8.0.4)
Requirement already satisfied: h11&gt;=0.8 in c:\users\vanu\anaconda3\lib\site-packages (from uvicorn) (0.14.0)
Requirement already satisfied: colorama in c:\users\vanu\anaconda3\lib\site-packages (from click&gt;=7.0-&gt;uvicorn) (0.4.6)
Requirement already satisfied: annotated-types&gt;=0.6.0 in c:\users\vanu\anaconda3\lib\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,&lt;3.0.0,&gt;=1.7.4-&gt;fastapi) (0.7.0)
Requirement already satisfied: pydantic-core==2.27.2 in c:\users\vanu\anaconda3\lib\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,&lt;3.0.0,&gt;=1.7.4-&gt;fastapi) (2.27.2)
Requirement already satisfied: anyio&lt;5,&gt;=3.4.0 in c:\users\vanu\anaconda3\lib\site-packages (from starlette&lt;0.42.0,&gt;=0.40.0-&gt;fastapi) (3.5.0)
Requirement already satisfied: idna&gt;=2.8 in c:\users\vanu\anaconda3\lib\site-packages (from anyio&lt;5,&gt;=3.4.0-&gt;starlette&lt;0.42.0,&gt;=0.40.0-&gt;fastapi) (3.4)
Requirement already satisfied: sniffio&gt;=1.1 in c:\users\vanu\anaconda3\lib\site-packages (from anyio&lt;5,&gt;=3.4.0-&gt;starlette&lt;0.42.0,&gt;=0.40.0-&gt;fastapi) (1.2.0)
Downloading fastapi-0.115.6-py3-none-any.whl (94 kB)
   ---------------------------------------- 0.0/94.8 kB ? eta -:--:--
   ----------------- ---------------------- 41.0/94.8 kB 991.0 kB/s eta 0:00:01
   ----------------- ---------------------- 41.0/94.8 kB 991.0 kB/s eta 0:00:01
   ----------------- ---------------------- 41.0/94.8 kB 991.0 kB/s eta 0:00:01
   ------------------------- -------------- 61.4/94.8 kB 297.7 kB/s eta 0:00:01
   ---------------------------------------- 94.8/94.8 kB 416.8 kB/s eta 0:00:00
Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)
   ---------------------------------------- 0.0/62.3 kB ? eta -:--:--
   -------------------------- ------------- 41.0/62.3 kB 960.0 kB/s eta 0:00:01
   ---------------------------------------- 62.3/62.3 kB 1.1 MB/s eta 0:00:00
Downloading starlette-0.41.3-py3-none-any.whl (73 kB)
   ---------------------------------------- 0.0/73.2 kB ? eta -:--:--
   ---------------------------------------- 73.2/73.2 kB 2.0 MB/s eta 0:00:00
Installing collected packages: uvicorn, starlette, fastapi
Successfully installed fastapi-0.115.6 starlette-0.41.3 uvicorn-0.34.0
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>--upgrade<span class="w"> </span>typing-extensions
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: typing-extensions in c:\users\vanu\anaconda3\lib\site-packages (4.12.2)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">subprocess</span>

<span class="c1"># Run FastAPI server using subprocess (this will run it in the background)</span>
<span class="n">subprocess</span><span class="o">.</span><span class="n">Popen</span><span class="p">([</span><span class="s1">&#39;uvicorn&#39;</span><span class="p">,</span> <span class="s1">&#39;app:app&#39;</span><span class="p">,</span> <span class="s1">&#39;--reload&#39;</span><span class="p">,</span> <span class="s1">&#39;--host&#39;</span><span class="p">,</span> <span class="s1">&#39;0.0.0.0&#39;</span><span class="p">,</span> <span class="s1">&#39;--port&#39;</span><span class="p">,</span> <span class="s1">&#39;8000&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Popen: returncode: None args: [&#39;uvicorn&#39;, &#39;app:app&#39;, &#39;--reload&#39;, &#39;--host&#39;, ...&gt;
</pre></div>
</div>
</div>
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="video.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">&lt;no title&gt;</p>
      </div>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">STEP-1 CREATING A NORMALIZED DATABASE</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#step-2-sql-join-statement-to-fetch-data-from-the-database-and-into-pandas-dataframe">STEP-2 SQL join statement to fetch data from the database and into Pandas DataFrame.</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#step-3-exploring-the-data">STEP-3 EXPLORING THE DATA</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4-exploring-the-data-using-yprofile-and-correlation-matrix-make-observations-about-features-distributions-capped-values-and-missing-values-create-a-list-of-data-cleanup-tasks">STEP-4 Exploring the data using yprofile and correlation matrix. Make observations about features, distributions, capped values, and missing values. Create a list of data cleanup tasks.</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#the-correlation-matrix-reveals-notable-trends-such-as-a-moderate-positive-correlation-between-sex-and-smoking-0-52-suggesting-gender-based-smoking-habits-and-a-negative-correlation-between-smoking-and-age-0-40-indicating-younger-individuals-are-more-likely-to-smoke-features-like-systolic-and-diastolic-blood-pressure-show-expected-correlations-while-attributes-such-as-cholesterol-heartrate-and-exercisehoursperweek-exhibit-very-weak-correlations-with-other-features-suggesting-limited-influence-continuous-features-like-age-bmi-income-and-sedentaryhoursperday-show-varied-ranges-and-potential-outliers-e-g-capped-values-for-exercisehoursperweek-around-20-while-the-dataset-has-no-missing-values-scaling-and-normalization-are-necessary-for-numerical-features-and-redundant-features-like-sex-and-smoking-require-furtherinvestigation-to-assess-their-impact-additionally-extreme-values-in-triglycerides-and-sedentaryhours-should-be-explored-and-low-impact-features-may-be-considered-for-removal-to-streamline-the-model">The correlation matrix reveals notable trends, such as a moderate positive correlation between Sex and Smoking (0.52), suggesting gender-based smoking habits, and a negative correlation between Smoking and Age (-0.40), indicating younger individuals are more likely to smoke. Features like Systolic and Diastolic blood pressure show expected correlations, while attributes such as Cholesterol, HeartRate, and ExerciseHoursPerWeek exhibit very weak correlations with other features, suggesting limited influence. Continuous features like Age, BMI, Income, and SedentaryHoursPerDay show varied ranges and potential outliers (e.g., capped values for ExerciseHoursPerWeek around 20). While the dataset has no missing values, scaling and normalization are necessary for numerical features, and redundant features like Sex and Smoking require furtherinvestigation to assess their impact. Additionally, extreme values in Triglycerides and SedentaryHours should be explored, and low-impact features may be considered for removal to streamline the model.</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#step-5-exp-1-calculating-f-score-tp-tn-fn-fp-in-mlflow-on-dagshub">STEP-5 EXP-1 calculating f-score,(TP,TN,FN,FP)in MLFlow on DagsHub</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#this-focuses-on-building-a-logistic-regression-model-to-classify-the-iris-dataset-into-three-species-setosa-versicolor-and-virginica-the-preprocessing-pipeline-includes-log-transformation-to-reduce-skewness-standard-scaling-for-normalization-minmax-scaling-to-bring-numerical-features-to-a-uniform-range-and-onehotencoding-for-categorical-features-hyperparameter-tuning-is-conducted-using-gridsearchcv-with-3-fold-cross-validation-to-find-the-optimal-regularization-parameter-c-which-was-determined-to-be-100-the-model-s-performance-is-evaluated-using-accuracy-weighted-f1-score-and-confusion-matrix-components-tp-tn-fp-fn-for-each-class-the-final-model-achieved-an-accuracy-of-96-67-and-a-weighted-f1-score-of-96-67-with-minimal-misclassifications-observed-in-versicolor-and-virginica-all-parameters-metrics-and-results-including-the-confusion-matrix-are-logged-to-mlflow-for-experiment-tracking-and-reproducibility-this-experiment-demonstrates-a-robust-approach-to-multi-class-classification-with-effective-preprocessing-and-evaluation-strategies">This focuses on building a Logistic Regression model to classify the Iris dataset into three species: Setosa, Versicolor, and Virginica. The preprocessing pipeline includes log transformation to reduce skewness, standard scaling for normalization, MinMax scaling to bring numerical features to a uniform range, and OneHotEncoding for categorical features. Hyperparameter tuning is conducted using GridSearchCV with 3-fold cross-validation to find the optimal regularization parameter (C), which was determined to be 100. The modelâ€™s performance is evaluated using accuracy, weighted F1-score, and confusion matrix components (TP, TN, FP, FN) for each class. The final model achieved an accuracy of 96.67% and a weighted F1-score of 96.67%, with minimal misclassifications observed in Versicolor and Virginica. All parameters, metrics, and results, including the confusion matrix, are logged to MLFlow for experiment tracking and reproducibility. This experiment demonstrates a robust approach to multi-class classification with effective preprocessing and evaluation strategies.</a></li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Vinuthna Reddy Ryala
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      Â© Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>